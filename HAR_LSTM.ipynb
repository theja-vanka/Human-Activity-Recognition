{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activities are the class labels\n",
    "# It is a 6 class classification\n",
    "ACTIVITIES = {\n",
    "    0: 'WALKING',\n",
    "    1: 'WALKING_UPSTAIRS',\n",
    "    2: 'WALKING_DOWNSTAIRS',\n",
    "    3: 'SITTING',\n",
    "    4: 'STANDING',\n",
    "    5: 'LAYING',\n",
    "}\n",
    "\n",
    "# Utility function to print the confusion matrix\n",
    "def confusion_matrix(Y_true, Y_pred):\n",
    "    Y_true = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_true, axis=1)])\n",
    "    Y_pred = pd.Series([ACTIVITIES[y] for y in np.argmax(Y_pred, axis=1)])\n",
    "\n",
    "    return pd.crosstab(Y_true, Y_pred, rownames=['True'], colnames=['Pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directory\n",
    "DATADIR = 'UCI_HAR_Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data signals\n",
    "# Signals are from Accelerometer and Gyroscope\n",
    "# The signals are in x,y,z directions\n",
    "# Sensor signals are filtered to have only body acceleration\n",
    "# excluding the acceleration due to gravity\n",
    "# Triaxial acceleration from the accelerometer is total acceleration\n",
    "SIGNALS = [\n",
    "    \"body_acc_x\",\n",
    "    \"body_acc_y\",\n",
    "    \"body_acc_z\",\n",
    "    \"body_gyro_x\",\n",
    "    \"body_gyro_y\",\n",
    "    \"body_gyro_z\",\n",
    "    \"total_acc_x\",\n",
    "    \"total_acc_y\",\n",
    "    \"total_acc_z\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to read the data from csv file\n",
    "def _read_csv(filename):\n",
    "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "\n",
    "# Utility function to load the load\n",
    "def load_signals(subset):\n",
    "    signals_data = []\n",
    "\n",
    "    for signal in SIGNALS:\n",
    "        filename = f'UCI_HAR_Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
    "        signals_data.append(\n",
    "            _read_csv(filename).as_matrix()\n",
    "        ) \n",
    "\n",
    "    # Transpose is used to change the dimensionality of the output,\n",
    "    # aggregating the signals by combination of sample/timestep.\n",
    "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
    "    return np.transpose(signals_data, (1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_y(subset):\n",
    "    \"\"\"\n",
    "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
    "    that represents a human activity. We return a binary representation of \n",
    "    every sample objective as a 6 bits vector using One Hot Encoding\n",
    "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
    "    \"\"\"\n",
    "    filename = f'UCI_HAR_Dataset/{subset}/y_{subset}.txt'\n",
    "    y = _read_csv(filename)[0]\n",
    "\n",
    "    return pd.get_dummies(y).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Obtain the dataset from multiple files.\n",
    "    Returns: X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    X_train, X_test = load_signals('train'), load_signals('test')\n",
    "    y_train, y_test = load_y('train'), load_y('test')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing tensorflow\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Keras\n",
    "from keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Conv2D, MaxPooling2D, Flatten,Conv1D,MaxPooling1D,TimeDistributed\n",
    "from keras.layers.core import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 30\n",
    "batch_size = 16\n",
    "n_hidden = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:12: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Loading the train and test data\n",
    "X_train, X_test, Y_train, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "9\n",
      "7352\n"
     ]
    }
   ],
   "source": [
    "timesteps = len(X_train[0])\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "\n",
    "print(timesteps)\n",
    "print(input_dim)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7352\n",
      "128\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_train[0]))\n",
    "print(len(X_train[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = X_train.reshape((len(X_train), 4,32, input_dim))\n",
    "testX = X_test.reshape((len(X_test), 4, 32, input_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Defining the Architecture of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 32)                5376      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 198       \n",
      "=================================================================\n",
      "Total params: 5,574\n",
      "Trainable params: 5,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(LSTM(n_hidden, input_shape=(timesteps, input_dim)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 34s 5ms/step - loss: 1.3306 - acc: 0.4361 - val_loss: 1.1743 - val_acc: 0.4723\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 0.9716 - acc: 0.5788 - val_loss: 0.9656 - val_acc: 0.5263\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.7787 - acc: 0.6510 - val_loss: 0.7841 - val_acc: 0.6135\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.6911 - acc: 0.6587 - val_loss: 0.7109 - val_acc: 0.6203\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 26s 3ms/step - loss: 0.6496 - acc: 0.6794 - val_loss: 0.8000 - val_acc: 0.6362\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.8295 - acc: 0.6221 - val_loss: 0.7970 - val_acc: 0.6318\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.5920 - acc: 0.7122 - val_loss: 0.6816 - val_acc: 0.7038\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.5472 - acc: 0.7594 - val_loss: 0.6473 - val_acc: 0.7258\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 28s 4ms/step - loss: 0.4838 - acc: 0.7805 - val_loss: 0.6033 - val_acc: 0.7445\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 0.4212 - acc: 0.7907 - val_loss: 0.5396 - val_acc: 0.7472\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.3967 - acc: 0.8084 - val_loss: 0.5399 - val_acc: 0.7526\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.3609 - acc: 0.8407 - val_loss: 0.5420 - val_acc: 0.8222\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.3312 - acc: 0.8798 - val_loss: 0.5038 - val_acc: 0.8673\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 26s 3ms/step - loss: 0.3000 - acc: 0.9053 - val_loss: 0.4823 - val_acc: 0.8758\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 26s 4ms/step - loss: 0.2574 - acc: 0.9230 - val_loss: 0.5465 - val_acc: 0.8731\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.2383 - acc: 0.9293 - val_loss: 0.5054 - val_acc: 0.8694\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.2271 - acc: 0.9313 - val_loss: 0.5409 - val_acc: 0.8653\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.2121 - acc: 0.9353 - val_loss: 0.5611 - val_acc: 0.8677\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.2129 - acc: 0.9355 - val_loss: 0.5293 - val_acc: 0.8887\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 31s 4ms/step - loss: 0.1825 - acc: 0.9425 - val_loss: 0.4945 - val_acc: 0.8656\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1857 - acc: 0.9400 - val_loss: 0.4470 - val_acc: 0.8836\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1827 - acc: 0.9445 - val_loss: 0.7009 - val_acc: 0.8517\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 24s 3ms/step - loss: 0.1909 - acc: 0.9391 - val_loss: 0.5290 - val_acc: 0.8884\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 25s 3ms/step - loss: 0.1925 - acc: 0.9399 - val_loss: 0.6053 - val_acc: 0.8812\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 27s 4ms/step - loss: 0.1821 - acc: 0.9440 - val_loss: 0.4675 - val_acc: 0.8765\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1773 - acc: 0.9448 - val_loss: 0.5316 - val_acc: 0.8826\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.1817 - acc: 0.9406 - val_loss: 0.5282 - val_acc: 0.8843\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1966 - acc: 0.9402 - val_loss: 0.5390 - val_acc: 0.8931\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 30s 4ms/step - loss: 0.2257 - acc: 0.9291 - val_loss: 0.4739 - val_acc: 0.8948\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 29s 4ms/step - loss: 0.1745 - acc: 0.9442 - val_loss: 0.4692 - val_acc: 0.8806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x104ed6940>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 510        0         0        0                   0   \n",
      "SITTING                  0      398        66        0                   0   \n",
      "STANDING                 0      100       418        2                   0   \n",
      "WALKING                  0        3         0      465                   8   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 360   \n",
      "WALKING_UPSTAIRS         0        3         0       23                   1   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                            27  \n",
      "SITTING                           27  \n",
      "STANDING                          12  \n",
      "WALKING                           20  \n",
      "WALKING_DOWNSTAIRS                60  \n",
      "WALKING_UPSTAIRS                 444  \n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 1s 305us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4692274864947224, 0.8805564981336953]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- With a simple 2 layer architecture we got 90.09% accuracy and a loss of 0.30\n",
    "- We can further imporve the performace with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Layer Hyper Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./tmp/X_train\", X_train)\n",
    "np.save(\"./tmp/Y_train\", Y_train)\n",
    "np.save(\"./tmp/X_test\", X_test)\n",
    "np.save(\"./tmp/Y_test\", Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    x_train = np.load(\"./tmp/X_train.npy\")\n",
    "    y_train = np.load(\"./tmp/Y_train.npy\")\n",
    "    x_test = np.load(\"./tmp/X_test.npy\")\n",
    "    y_test = np.load(\"./tmp/Y_test.npy\")\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "# Reference - https://github.com/maxpumperla/hyperas\n",
    "\n",
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    epochs = 30\n",
    "    batch_size = 16\n",
    "    timesteps = x_train.shape[1]\n",
    "    input_dim = len(x_train[0][0])\n",
    "    n_classes = 6\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM({{choice([64, 32, 16])}}, input_shape=(timesteps, input_dim)))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    model.add(Dense(n_classes, activation='sigmoid'))\n",
    "    print(model.summary())\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    # ... model fitting\n",
    "    \n",
    "    history = model.fit(x_train, y_train, batch_size = batch_size, epochs=epochs, verbose=2, validation_data=(x_test, y_test))\n",
    "    validation_acc = np.amax(history.history['val_acc'])\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import LSTM\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'LSTM': hp.choice('LSTM', [64, 32, 16]),\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: x_train = np.load(\"./tmp/X_train.npy\")\n",
      "  3: y_train = np.load(\"./tmp/Y_train.npy\")\n",
      "  4: x_test = np.load(\"./tmp/X_test.npy\")\n",
      "  5: y_test = np.load(\"./tmp/Y_test.npy\")\n",
      "  6: \n",
      "  7: \n",
      "  8: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "  1: def keras_fmin_fnct(space):\n",
      "  2: \n",
      "  3:     \n",
      "  4:     epochs = 30\n",
      "  5:     batch_size = 16\n",
      "  6:     timesteps = x_train.shape[1]\n",
      "  7:     input_dim = len(x_train[0][0])\n",
      "  8:     n_classes = 6\n",
      "  9:     \n",
      " 10:     model = Sequential()\n",
      " 11:     model.add(LSTM(space['LSTM'], input_shape=(timesteps, input_dim)))\n",
      " 12:     model.add(Dropout(space['Dropout']))\n",
      " 13:     model.add(Dense(n_classes, activation='sigmoid'))\n",
      " 14:     print(model.summary())\n",
      " 15:     model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
      " 16:     # ... model fitting\n",
      " 17:     \n",
      " 18:     history = model.fit(x_train, y_train, batch_size = batch_size, epochs=epochs, verbose=2, validation_data=(x_test, y_test))\n",
      " 19:     validation_acc = np.amax(history.history['val_acc'])\n",
      " 20:     return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n",
      " 21: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_6 (LSTM)                (None, 16)                1664      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 1,766                                \n",
      "Trainable params: 1,766                            \n",
      "Non-trainable params: 0                            \n",
      "_________________________________________________________________\n",
      "None                                               \n",
      "Train on 7352 samples, validate on 2947 samples    \n",
      "Epoch 1/30                                         \n",
      " - 22s - loss: 1.4181 - acc: 0.4426 - val_loss: 1.2250 - val_acc: 0.4438\n",
      "\n",
      "Epoch 2/30                                         \n",
      " - 22s - loss: 1.0958 - acc: 0.5390 - val_loss: 1.0571 - val_acc: 0.5348\n",
      "\n",
      "Epoch 3/30                                         \n",
      " - 21s - loss: 0.9197 - acc: 0.6328 - val_loss: 0.9134 - val_acc: 0.6230\n",
      "\n",
      "Epoch 4/30                                         \n",
      " - 21s - loss: 0.7587 - acc: 0.6862 - val_loss: 0.8278 - val_acc: 0.6420\n",
      "\n",
      "Epoch 5/30                                         \n",
      " - 21s - loss: 0.6856 - acc: 0.7112 - val_loss: 0.8437 - val_acc: 0.6345\n",
      "\n",
      "Epoch 6/30                                         \n",
      " - 21s - loss: 0.6339 - acc: 0.7315 - val_loss: 0.7031 - val_acc: 0.7136\n",
      "\n",
      "Epoch 7/30                                         \n",
      " - 21s - loss: 0.5732 - acc: 0.7655 - val_loss: 0.6571 - val_acc: 0.7262\n",
      "\n",
      "Epoch 8/30                                         \n",
      " - 26s - loss: 0.5185 - acc: 0.7803 - val_loss: 0.6590 - val_acc: 0.7445\n",
      "\n",
      "Epoch 9/30                                         \n",
      " - 23s - loss: 0.4775 - acc: 0.7863 - val_loss: 0.6188 - val_acc: 0.7350\n",
      "\n",
      "Epoch 10/30                                        \n",
      " - 26s - loss: 0.4484 - acc: 0.7919 - val_loss: 0.6282 - val_acc: 0.7357\n",
      "\n",
      "Epoch 11/30                                        \n",
      " - 22s - loss: 0.4323 - acc: 0.7996 - val_loss: 0.5921 - val_acc: 0.7435\n",
      "\n",
      "Epoch 12/30                                        \n",
      " - 21s - loss: 0.4135 - acc: 0.8078 - val_loss: 0.5650 - val_acc: 0.7452\n",
      "\n",
      "Epoch 13/30                                        \n",
      " - 21s - loss: 0.3992 - acc: 0.8169 - val_loss: 0.5999 - val_acc: 0.7547\n",
      "\n",
      "Epoch 14/30                                        \n",
      " - 21s - loss: 0.4034 - acc: 0.8094 - val_loss: 0.6064 - val_acc: 0.7631\n",
      "\n",
      "Epoch 15/30                                        \n",
      " - 21s - loss: 0.3913 - acc: 0.8258 - val_loss: 0.6027 - val_acc: 0.7679\n",
      "\n",
      "Epoch 16/30                                        \n",
      " - 21s - loss: 0.3875 - acc: 0.8444 - val_loss: 0.6290 - val_acc: 0.8219\n",
      "\n",
      "Epoch 17/30                                        \n",
      " - 21s - loss: 0.3690 - acc: 0.8621 - val_loss: 0.5285 - val_acc: 0.8375\n",
      "\n",
      "Epoch 18/30                                        \n",
      " - 21s - loss: 0.3203 - acc: 0.8847 - val_loss: 0.5478 - val_acc: 0.8419\n",
      "\n",
      "Epoch 19/30                                        \n",
      " - 21s - loss: 0.2968 - acc: 0.9029 - val_loss: 0.5359 - val_acc: 0.8266\n",
      "\n",
      "Epoch 20/30                                        \n",
      " - 21s - loss: 0.2781 - acc: 0.9112 - val_loss: 0.4906 - val_acc: 0.8541\n",
      "\n",
      "Epoch 21/30                                        \n",
      " - 21s - loss: 0.2451 - acc: 0.9174 - val_loss: 0.4923 - val_acc: 0.8599\n",
      "\n",
      "Epoch 22/30                                        \n",
      " - 21s - loss: 0.2466 - acc: 0.9184 - val_loss: 0.5128 - val_acc: 0.8548\n",
      "\n",
      "Epoch 23/30                                        \n",
      " - 21s - loss: 0.2456 - acc: 0.9214 - val_loss: 0.4693 - val_acc: 0.8568\n",
      "\n",
      "Epoch 24/30                                        \n",
      " - 21s - loss: 0.2318 - acc: 0.9268 - val_loss: 0.4425 - val_acc: 0.8704\n",
      "\n",
      "Epoch 25/30                                        \n",
      " - 21s - loss: 0.2377 - acc: 0.9226 - val_loss: 0.3757 - val_acc: 0.8782\n",
      "\n",
      "Epoch 26/30                                        \n",
      " - 22s - loss: 0.2088 - acc: 0.9295 - val_loss: 0.4998 - val_acc: 0.8744\n",
      "\n",
      "Epoch 27/30                                        \n",
      " - 22s - loss: 0.2051 - acc: 0.9335 - val_loss: 0.4520 - val_acc: 0.8809\n",
      "\n",
      "Epoch 28/30                                        \n",
      " - 21s - loss: 0.2059 - acc: 0.9327 - val_loss: 0.6362 - val_acc: 0.8402\n",
      "\n",
      "Epoch 29/30                                        \n",
      " - 21s - loss: 0.2201 - acc: 0.9312 - val_loss: 0.4299 - val_acc: 0.8829\n",
      "\n",
      "Epoch 30/30                                        \n",
      " - 21s - loss: 0.1900 - acc: 0.9366 - val_loss: 0.4266 - val_acc: 0.8823\n",
      "\n",
      "_________________________________________________________________             \n",
      "Layer (type)                 Output Shape              Param #                \n",
      "=================================================================             \n",
      "lstm_7 (LSTM)                (None, 64)                18944                  \n",
      "_________________________________________________________________             \n",
      "dropout_7 (Dropout)          (None, 64)                0                      \n",
      "_________________________________________________________________             \n",
      "dense_7 (Dense)              (None, 6)                 390                    \n",
      "=================================================================             \n",
      "Total params: 19,334                                                          \n",
      "Trainable params: 19,334                                                      \n",
      "Non-trainable params: 0                                                       \n",
      "_________________________________________________________________             \n",
      "None                                                                          \n",
      "Train on 7352 samples, validate on 2947 samples                               \n",
      "Epoch 1/30                                                                    \n",
      " - 27s - loss: 1.1528 - acc: 0.5029 - val_loss: 0.9494 - val_acc: 0.6172      \n",
      "\n",
      "Epoch 2/30                                                                    \n",
      " - 26s - loss: 0.7921 - acc: 0.6634 - val_loss: 0.7129 - val_acc: 0.7313      \n",
      "\n",
      "Epoch 3/30                                                                    \n",
      " - 26s - loss: 0.6238 - acc: 0.7801 - val_loss: 0.5944 - val_acc: 0.8225      \n",
      "\n",
      "Epoch 4/30                                                                    \n",
      " - 26s - loss: 0.3943 - acc: 0.8757 - val_loss: 0.4600 - val_acc: 0.8497      \n",
      "\n",
      "Epoch 5/30                                                                    \n",
      " - 26s - loss: 0.2997 - acc: 0.9044 - val_loss: 0.3765 - val_acc: 0.8836      \n",
      "\n",
      "Epoch 6/30                                                                    \n",
      " - 26s - loss: 0.2279 - acc: 0.9227 - val_loss: 0.3043 - val_acc: 0.8833      \n",
      "\n",
      "Epoch 7/30                                                                    \n",
      " - 26s - loss: 0.2107 - acc: 0.9300 - val_loss: 0.3541 - val_acc: 0.8823      \n",
      "\n",
      "Epoch 8/30                                                                    \n",
      " - 26s - loss: 0.1815 - acc: 0.9382 - val_loss: 0.2402 - val_acc: 0.9053      \n",
      "\n",
      "Epoch 9/30                                                                    \n",
      " - 26s - loss: 0.1754 - acc: 0.9374 - val_loss: 0.2776 - val_acc: 0.9040      \n",
      "\n",
      "Epoch 10/30                                                                   \n",
      " - 26s - loss: 0.1781 - acc: 0.9370 - val_loss: 0.3430 - val_acc: 0.9046      \n",
      "\n",
      "Epoch 11/30                                                                   \n",
      " - 27s - loss: 0.1527 - acc: 0.9433 - val_loss: 0.2582 - val_acc: 0.9179      \n",
      "\n",
      "Epoch 12/30                                                                   \n",
      " - 27s - loss: 0.1432 - acc: 0.9453 - val_loss: 0.3067 - val_acc: 0.9087      \n",
      "\n",
      "Epoch 13/30                                                                   \n",
      " - 27s - loss: 0.1559 - acc: 0.9470 - val_loss: 0.2659 - val_acc: 0.9040      \n",
      "\n",
      "Epoch 14/30                                                                   \n",
      " - 27s - loss: 0.1360 - acc: 0.9489 - val_loss: 0.3567 - val_acc: 0.8924      \n",
      "\n",
      "Epoch 15/30                                                                   \n",
      " - 27s - loss: 0.1302 - acc: 0.9489 - val_loss: 0.3589 - val_acc: 0.9030      \n",
      "\n",
      "Epoch 16/30                                                                   \n",
      " - 26s - loss: 0.1258 - acc: 0.9520 - val_loss: 0.3325 - val_acc: 0.9036      \n",
      "\n",
      "Epoch 17/30                                                                   \n",
      " - 30s - loss: 0.1191 - acc: 0.9527 - val_loss: 0.4162 - val_acc: 0.9070      \n",
      "\n",
      "Epoch 18/30                                                                   \n",
      " - 26s - loss: 0.1332 - acc: 0.9513 - val_loss: 0.4133 - val_acc: 0.8979      \n",
      "\n",
      "Epoch 19/30                                                                   \n",
      " - 29s - loss: 0.1271 - acc: 0.9482 - val_loss: 0.4092 - val_acc: 0.9026      \n",
      "\n",
      "Epoch 20/30                                                                   \n",
      " - 27s - loss: 0.1366 - acc: 0.9493 - val_loss: 0.3244 - val_acc: 0.9067      \n",
      "\n",
      "Epoch 21/30                                                                   \n",
      " - 26s - loss: 0.1397 - acc: 0.9508 - val_loss: 0.3714 - val_acc: 0.9060      \n",
      "\n",
      "Epoch 22/30                                                                   \n",
      " - 26s - loss: 0.1250 - acc: 0.9532 - val_loss: 0.4326 - val_acc: 0.9087      \n",
      "\n",
      "Epoch 23/30                                                                   \n",
      " - 26s - loss: 0.1198 - acc: 0.9557 - val_loss: 0.4049 - val_acc: 0.9080      \n",
      "\n",
      "Epoch 24/30                                                                   \n",
      " - 27s - loss: 0.1185 - acc: 0.9554 - val_loss: 0.5537 - val_acc: 0.8918      \n",
      "\n",
      "Epoch 25/30                                                                   \n",
      " - 27s - loss: 0.1336 - acc: 0.9516 - val_loss: 0.4524 - val_acc: 0.9002      \n",
      "\n",
      "Epoch 26/30                                                                   \n",
      " - 26s - loss: 0.1327 - acc: 0.9525 - val_loss: 0.3667 - val_acc: 0.9097      \n",
      "\n",
      "Epoch 27/30                                                                   \n",
      " - 26s - loss: 0.1367 - acc: 0.9514 - val_loss: 0.4059 - val_acc: 0.9135      \n",
      "\n",
      "Epoch 28/30                                                                   \n",
      " - 27s - loss: 0.1412 - acc: 0.9494 - val_loss: 0.4896 - val_acc: 0.8989      \n",
      "\n",
      "Epoch 29/30                                                                   \n",
      " - 27s - loss: 0.1419 - acc: 0.9486 - val_loss: 0.3142 - val_acc: 0.9152      \n",
      "\n",
      "Epoch 30/30                                                                   \n",
      " - 26s - loss: 0.1398 - acc: 0.9516 - val_loss: 0.3218 - val_acc: 0.9199      \n",
      "\n",
      "_________________________________________________________________             \n",
      "Layer (type)                 Output Shape              Param #                \n",
      "=================================================================             \n",
      "lstm_8 (LSTM)                (None, 32)                5376                   \n",
      "_________________________________________________________________             \n",
      "dropout_8 (Dropout)          (None, 32)                0                      \n",
      "_________________________________________________________________             \n",
      "dense_8 (Dense)              (None, 6)                 198                    \n",
      "=================================================================             \n",
      "Total params: 5,574                                                           \n",
      "Trainable params: 5,574                                                       \n",
      "Non-trainable params: 0                                                       \n",
      "_________________________________________________________________             \n",
      "None                                                                          \n",
      "Train on 7352 samples, validate on 2947 samples                               \n",
      "Epoch 1/30                                                                    \n",
      " - 24s - loss: 1.4421 - acc: 0.4055 - val_loss: 1.2122 - val_acc: 0.4499      \n",
      "\n",
      "Epoch 2/30                                                                    \n",
      " - 23s - loss: 1.1989 - acc: 0.4816 - val_loss: 1.1084 - val_acc: 0.5209      \n",
      "\n",
      "Epoch 3/30                                                                    \n",
      " - 23s - loss: 1.0463 - acc: 0.5494 - val_loss: 0.9952 - val_acc: 0.5901      \n",
      "\n",
      "Epoch 4/30                                                                    \n",
      " - 23s - loss: 1.1030 - acc: 0.5248 - val_loss: 1.3211 - val_acc: 0.3475      \n",
      "\n",
      "Epoch 5/30                                                                    \n",
      " - 23s - loss: 0.9116 - acc: 0.6034 - val_loss: 0.8685 - val_acc: 0.5830      \n",
      "\n",
      "Epoch 6/30                                                                    \n",
      " - 23s - loss: 0.8460 - acc: 0.6167 - val_loss: 0.7976 - val_acc: 0.6213      \n",
      "\n",
      "Epoch 7/30                                                                    \n",
      " - 26s - loss: 0.7853 - acc: 0.6323 - val_loss: 0.7972 - val_acc: 0.6111      \n",
      "\n",
      "Epoch 8/30                                                                    \n",
      " - 29s - loss: 0.7552 - acc: 0.6522 - val_loss: 0.7674 - val_acc: 0.6237      \n",
      "\n",
      "Epoch 9/30                                                                    \n",
      " - 30s - loss: 0.7196 - acc: 0.6639 - val_loss: 0.7933 - val_acc: 0.6220      \n",
      "\n",
      "Epoch 10/30                                                                   \n",
      " - 23s - loss: 0.7080 - acc: 0.6795 - val_loss: 0.8886 - val_acc: 0.6257      \n",
      "\n",
      "Epoch 11/30                                                                   \n",
      " - 24s - loss: 0.6796 - acc: 0.6984 - val_loss: 0.7922 - val_acc: 0.7024      \n",
      "\n",
      "Epoch 12/30                                                                   \n",
      " - 23s - loss: 0.6391 - acc: 0.7329 - val_loss: 0.7733 - val_acc: 0.7136      \n",
      "\n",
      "Epoch 13/30                                                                   \n",
      " - 27s - loss: 0.6275 - acc: 0.7403 - val_loss: 0.7517 - val_acc: 0.7282      \n",
      "\n",
      "Epoch 14/30                                                                   \n",
      " - 26s - loss: 0.6045 - acc: 0.7675 - val_loss: 0.6580 - val_acc: 0.7567      \n",
      "\n",
      "Epoch 15/30                                                                   \n",
      " - 28s - loss: 0.6021 - acc: 0.7852 - val_loss: 0.6070 - val_acc: 0.8117      \n",
      "\n",
      "Epoch 16/30                                                                   \n",
      " - 29s - loss: 0.5705 - acc: 0.7923 - val_loss: 0.6245 - val_acc: 0.8222      \n",
      "\n",
      "Epoch 17/30                                                                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 23s - loss: 0.5146 - acc: 0.8211 - val_loss: 0.5720 - val_acc: 0.8361      \n",
      "\n",
      "Epoch 18/30                                                                   \n",
      " - 23s - loss: 0.5210 - acc: 0.8326 - val_loss: 0.6667 - val_acc: 0.8334      \n",
      "\n",
      "Epoch 19/30                                                                   \n",
      " - 23s - loss: 0.4721 - acc: 0.8520 - val_loss: 0.6538 - val_acc: 0.8456      \n",
      "\n",
      "Epoch 20/30                                                                   \n",
      " - 26s - loss: 0.4444 - acc: 0.8658 - val_loss: 0.6144 - val_acc: 0.8215      \n",
      "\n",
      "Epoch 21/30                                                                   \n",
      " - 24s - loss: 0.4416 - acc: 0.8734 - val_loss: 0.5811 - val_acc: 0.8571      \n",
      "\n",
      "Epoch 22/30                                                                   \n",
      " - 30s - loss: 0.4092 - acc: 0.8832 - val_loss: 0.4342 - val_acc: 0.8738      \n",
      "\n",
      "Epoch 23/30                                                                   \n",
      " - 24s - loss: 0.3897 - acc: 0.8887 - val_loss: 0.9183 - val_acc: 0.8378      \n",
      "\n",
      "Epoch 24/30                                                                   \n",
      " - 27s - loss: nan - acc: 0.8551 - val_loss: nan - val_acc: 0.1683            \n",
      "\n",
      "Epoch 25/30                                                                   \n",
      " - 27s - loss: nan - acc: 0.1668 - val_loss: nan - val_acc: 0.1683            \n",
      "\n",
      "Epoch 26/30                                                                   \n",
      " - 27s - loss: nan - acc: 0.1668 - val_loss: nan - val_acc: 0.1683            \n",
      "\n",
      "Epoch 27/30                                                                   \n",
      " - 30s - loss: nan - acc: 0.1668 - val_loss: nan - val_acc: 0.1683            \n",
      "\n",
      "Epoch 28/30                                                                   \n",
      " - 29s - loss: nan - acc: 0.1668 - val_loss: nan - val_acc: 0.1683            \n",
      "\n",
      "Epoch 29/30                                                                   \n",
      " - 29s - loss: nan - acc: 0.1668 - val_loss: nan - val_acc: 0.1683            \n",
      "\n",
      "Epoch 30/30                                                                   \n",
      " - 28s - loss: nan - acc: 0.1668 - val_loss: nan - val_acc: 0.1683            \n",
      "\n",
      "_________________________________________________________________             \n",
      "Layer (type)                 Output Shape              Param #                \n",
      "=================================================================             \n",
      "lstm_9 (LSTM)                (None, 32)                5376                   \n",
      "_________________________________________________________________             \n",
      "dropout_9 (Dropout)          (None, 32)                0                      \n",
      "_________________________________________________________________             \n",
      "dense_9 (Dense)              (None, 6)                 198                    \n",
      "=================================================================             \n",
      "Total params: 5,574                                                           \n",
      "Trainable params: 5,574                                                       \n",
      "Non-trainable params: 0                                                       \n",
      "_________________________________________________________________             \n",
      "None                                                                          \n",
      "Train on 7352 samples, validate on 2947 samples                               \n",
      "Epoch 1/30                                                                    \n",
      " - 30s - loss: 1.3239 - acc: 0.4410 - val_loss: 1.1631 - val_acc: 0.5022      \n",
      "\n",
      "Epoch 2/30                                                                    \n",
      " - 26s - loss: 1.0351 - acc: 0.5476 - val_loss: 0.9988 - val_acc: 0.5840      \n",
      "\n",
      "Epoch 3/30                                                                    \n",
      " - 24s - loss: 0.8382 - acc: 0.6136 - val_loss: 0.8434 - val_acc: 0.6505      \n",
      "\n",
      "Epoch 4/30                                                                    \n",
      " - 26s - loss: 0.7551 - acc: 0.6526 - val_loss: 0.8050 - val_acc: 0.6332      \n",
      "\n",
      "Epoch 5/30                                                                    \n",
      " - 27s - loss: 0.6984 - acc: 0.6650 - val_loss: 0.7658 - val_acc: 0.6552      \n",
      "\n",
      "Epoch 6/30                                                                    \n",
      " - 28s - loss: 0.6971 - acc: 0.6662 - val_loss: 0.7527 - val_acc: 0.6417      \n",
      "\n",
      "Epoch 7/30                                                                    \n",
      " - 28s - loss: 0.6578 - acc: 0.6836 - val_loss: 0.7663 - val_acc: 0.6644      \n",
      "\n",
      "Epoch 8/30                                                                    \n",
      " - 26s - loss: 0.6813 - acc: 0.6624 - val_loss: 0.7608 - val_acc: 0.6271      \n",
      "\n",
      "Epoch 9/30                                                                    \n",
      " - 25s - loss: 0.7053 - acc: 0.6726 - val_loss: 0.7118 - val_acc: 0.7201      \n",
      "\n",
      "Epoch 10/30                                                                   \n",
      " - 24s - loss: 0.8069 - acc: 0.6693 - val_loss: 0.7598 - val_acc: 0.6274      \n",
      "\n",
      "Epoch 11/30                                                                   \n",
      " - 24s - loss: 0.5943 - acc: 0.7372 - val_loss: 0.6243 - val_acc: 0.7316      \n",
      "\n",
      "Epoch 12/30                                                                   \n",
      " - 24s - loss: 0.5518 - acc: 0.7665 - val_loss: 0.5450 - val_acc: 0.7567      \n",
      "\n",
      "Epoch 13/30                                                                   \n",
      " - 24s - loss: 0.4700 - acc: 0.8003 - val_loss: 0.6088 - val_acc: 0.7608      \n",
      "\n",
      "Epoch 14/30                                                                   \n",
      " - 24s - loss: 0.4325 - acc: 0.8252 - val_loss: 0.5777 - val_acc: 0.7893      \n",
      "\n",
      "Epoch 15/30                                                                   \n",
      " - 24s - loss: 0.4021 - acc: 0.8501 - val_loss: 0.5316 - val_acc: 0.8076      \n",
      "\n",
      "Epoch 16/30                                                                   \n",
      " - 24s - loss: 0.3514 - acc: 0.8885 - val_loss: 0.4710 - val_acc: 0.8310      \n",
      "\n",
      "Epoch 17/30                                                                   \n",
      " - 24s - loss: 0.3279 - acc: 0.9013 - val_loss: 0.5562 - val_acc: 0.7859      \n",
      "\n",
      "Epoch 18/30                                                                   \n",
      " - 24s - loss: 0.2880 - acc: 0.9112 - val_loss: 0.4827 - val_acc: 0.8605      \n",
      "\n",
      "Epoch 19/30                                                                   \n",
      " - 24s - loss: 0.2840 - acc: 0.9140 - val_loss: 0.4614 - val_acc: 0.8558      \n",
      "\n",
      "Epoch 20/30                                                                   \n",
      " - 24s - loss: 0.2664 - acc: 0.9155 - val_loss: 0.3792 - val_acc: 0.8616      \n",
      "\n",
      "Epoch 21/30                                                                   \n",
      " - 24s - loss: 0.2745 - acc: 0.9165 - val_loss: 0.4700 - val_acc: 0.8673      \n",
      "\n",
      "Epoch 22/30                                                                   \n",
      " - 23s - loss: 0.2157 - acc: 0.9321 - val_loss: 0.4522 - val_acc: 0.8626      \n",
      "\n",
      "Epoch 23/30                                                                   \n",
      " - 24s - loss: 0.2025 - acc: 0.9348 - val_loss: 0.5130 - val_acc: 0.8527      \n",
      "\n",
      "Epoch 24/30                                                                   \n",
      " - 24s - loss: 0.2057 - acc: 0.9355 - val_loss: 0.4265 - val_acc: 0.8622      \n",
      "\n",
      "Epoch 25/30                                                                   \n",
      " - 24s - loss: 0.1835 - acc: 0.9396 - val_loss: 0.4855 - val_acc: 0.8748      \n",
      "\n",
      "Epoch 26/30                                                                   \n",
      " - 24s - loss: 0.1699 - acc: 0.9406 - val_loss: 0.4114 - val_acc: 0.8870      \n",
      "\n",
      "Epoch 27/30                                                                   \n",
      " - 24s - loss: 0.1823 - acc: 0.9415 - val_loss: 0.3560 - val_acc: 0.8904      \n",
      "\n",
      "Epoch 28/30                                                                   \n",
      " - 24s - loss: 0.1772 - acc: 0.9429 - val_loss: 0.3424 - val_acc: 0.9013      \n",
      "\n",
      "Epoch 29/30                                                                   \n",
      " - 24s - loss: 0.1721 - acc: 0.9403 - val_loss: 0.3167 - val_acc: 0.8958      \n",
      "\n",
      "Epoch 30/30                                                                   \n",
      " - 24s - loss: 0.1956 - acc: 0.9418 - val_loss: 0.3690 - val_acc: 0.8911      \n",
      "\n",
      "100%|██████████| 4/4 [49:20<00:00, 724.06s/it, best loss: -0.9199185612487275]\n",
      "2947/2947 [==============================] - 1s 494us/step\n"
     ]
    }
   ],
   "source": [
    "best_run, best_model = optim.minimize(model=create_model, data=data, algo=tpe.suggest, max_evals=4, trials=Trials(), notebook_name = \"HAR_LSTM\")\n",
    "score = best_model.evaluate(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "|      Accuracy      |\n",
      "---------------------\n",
      "91.99%\n",
      "\n",
      "----------------------------------\n",
      "|      Best Hyper-Parameters      |\n",
      "----------------------------------\n",
      "{'Dropout': 0.23316134447477344, 'LSTM': 0}\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 64)                18944     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 19,334\n",
      "Trainable params: 19,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---------------------')\n",
    "print('|      Accuracy      |')\n",
    "print('---------------------')\n",
    "acc = np.round((score[1]*100), 2)\n",
    "print(str(acc)+\"%\\n\")\n",
    "    \n",
    "print('----------------------------------')\n",
    "print('|      Best Hyper-Parameters      |')\n",
    "print('----------------------------------')\n",
    "print(best_run)\n",
    "print(best_model.summary())\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "true_values = [np.argmax(i)+1 for i in Y_test]\n",
    "predicted_prob = best_model.predict(X_test)\n",
    "predicted_values = [np.argmax(i)+1 for i in predicted_prob]\n",
    "\n",
    "\n",
    "label = [\"WALKING\", \"WALKING_UPSTAIRS\", \"WALKING_DOWNSTAIRS\", \"SITTING\", \"STANDING\", \"LYING\"]\n",
    "frame_confusion = pd.DataFrame(confusion_matrix(true_values, predicted_values), index = label, columns = label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.heatmap(frame_confusion, annot = True, fmt=\"d\", cmap=\"YlGnBu\", linewidths=.5)\n",
    "plt.title(\"Test confusion matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Layer hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    x_train = np.load(\"./tmp/X_train.npy\")\n",
    "    y_train = np.load(\"./tmp/Y_train.npy\")\n",
    "    x_test = np.load(\"./tmp/X_test.npy\")\n",
    "    y_test = np.load(\"./tmp/Y_test.npy\")\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "# Reference - https://github.com/maxpumperla/hyperas\n",
    "\n",
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "    \n",
    "    epochs = 30\n",
    "    batch_size = 16\n",
    "    timesteps = x_train.shape[1]\n",
    "    input_dim = len(x_train[0][0])\n",
    "    n_classes = 6\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, return_sequences = True, input_shape = (timesteps, input_dim)))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))   \n",
    "    model.add(LSTM({{choice([64, 32, 16])}}))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    model.add(Dense(n_classes, activation='sigmoid'))\n",
    "    print(model.summary())\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    # ... model fitting\n",
    "    \n",
    "    history = model.fit(x_train, y_train, batch_size = batch_size, epochs=epochs, verbose=2, validation_data=(x_test, y_test))\n",
    "    validation_acc = np.amax(history.history['val_acc'])\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import LSTM\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import confusion_matrix\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import seaborn as sns\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'LSTM': hp.choice('LSTM', [64, 32, 16]),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: x_train = np.load(\"./tmp/X_train.npy\")\n",
      "  3: y_train = np.load(\"./tmp/Y_train.npy\")\n",
      "  4: x_test = np.load(\"./tmp/X_test.npy\")\n",
      "  5: y_test = np.load(\"./tmp/Y_test.npy\")\n",
      "  6: \n",
      "  7: \n",
      "  8: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "  1: def keras_fmin_fnct(space):\n",
      "  2: \n",
      "  3:     \n",
      "  4:     epochs = 30\n",
      "  5:     batch_size = 16\n",
      "  6:     timesteps = x_train.shape[1]\n",
      "  7:     input_dim = len(x_train[0][0])\n",
      "  8:     n_classes = 6\n",
      "  9:     \n",
      " 10:     model = Sequential()\n",
      " 11:     model.add(LSTM(64, return_sequences = True, input_shape = (timesteps, input_dim)))\n",
      " 12:     model.add(Dropout(space['Dropout']))   \n",
      " 13:     model.add(LSTM(space['LSTM']))\n",
      " 14:     model.add(Dropout(space['Dropout_1']))\n",
      " 15:     model.add(Dense(n_classes, activation='sigmoid'))\n",
      " 16:     print(model.summary())\n",
      " 17:     model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
      " 18:     # ... model fitting\n",
      " 19:     \n",
      " 20:     history = model.fit(x_train, y_train, batch_size = batch_size, epochs=epochs, verbose=2, validation_data=(x_test, y_test))\n",
      " 21:     validation_acc = np.amax(history.history['val_acc'])\n",
      " 22:     return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n",
      " 23: \n",
      "  0%|          | 0/4 [00:00<?, ?it/s, best loss: ?]WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128, 64)           18944     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 16)                5184      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 24,230                               \n",
      "Trainable params: 24,230                           \n",
      "Non-trainable params: 0                            \n",
      "_________________________________________________________________\n",
      "None                                               \n",
      "  0%|          | 0/4 [00:00<?, ?it/s, best loss: ?]WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 7352 samples, validate on 2947 samples    \n",
      "Epoch 1/30                                         \n",
      " - 62s - loss: 1.3127 - acc: 0.4804 - val_loss: 1.1648 - val_acc: 0.5219\n",
      "\n",
      "Epoch 2/30                                         \n",
      " - 56s - loss: 0.9484 - acc: 0.6537 - val_loss: 0.9783 - val_acc: 0.6464\n",
      "\n",
      "Epoch 3/30                                         \n",
      " - 55s - loss: 0.6763 - acc: 0.7549 - val_loss: 0.6509 - val_acc: 0.7920\n",
      "\n",
      "Epoch 4/30                                         \n",
      " - 58s - loss: 0.5011 - acc: 0.8241 - val_loss: 0.4861 - val_acc: 0.8504\n",
      "\n",
      "Epoch 5/30                                         \n",
      " - 54s - loss: 0.4796 - acc: 0.8606 - val_loss: 0.6035 - val_acc: 0.7998\n",
      "\n",
      "Epoch 6/30                                         \n",
      " - 54s - loss: 0.3035 - acc: 0.9155 - val_loss: 0.4294 - val_acc: 0.8728\n",
      "\n",
      "Epoch 7/30                                         \n",
      " - 54s - loss: 0.2579 - acc: 0.9221 - val_loss: 0.3600 - val_acc: 0.8823\n",
      "\n",
      "Epoch 8/30                                         \n",
      " - 54s - loss: 0.2223 - acc: 0.9340 - val_loss: 0.4901 - val_acc: 0.8582\n",
      "\n",
      "Epoch 9/30                                         \n",
      " - 54s - loss: 0.1958 - acc: 0.9395 - val_loss: 0.2488 - val_acc: 0.8989\n",
      "\n",
      "Epoch 10/30                                        \n",
      " - 54s - loss: 0.2005 - acc: 0.9392 - val_loss: 0.3199 - val_acc: 0.9067\n",
      "\n",
      "Epoch 11/30                                        \n",
      " - 54s - loss: 0.2158 - acc: 0.9359 - val_loss: 0.2573 - val_acc: 0.9019\n",
      "\n",
      "Epoch 12/30                                        \n",
      " - 54s - loss: 0.2039 - acc: 0.9387 - val_loss: 0.3033 - val_acc: 0.9013\n",
      "\n",
      "Epoch 13/30                                        \n",
      " - 54s - loss: 0.1825 - acc: 0.9450 - val_loss: 0.5536 - val_acc: 0.8775\n",
      "\n",
      "Epoch 14/30                                        \n",
      " - 54s - loss: 0.1788 - acc: 0.9414 - val_loss: 0.3784 - val_acc: 0.9097\n",
      "\n",
      "Epoch 15/30                                        \n",
      " - 54s - loss: 0.1562 - acc: 0.9460 - val_loss: 0.3758 - val_acc: 0.9128\n",
      "\n",
      "Epoch 16/30                                        \n",
      " - 54s - loss: 0.1795 - acc: 0.9385 - val_loss: 0.4061 - val_acc: 0.8935\n",
      "\n",
      "Epoch 17/30                                        \n",
      " - 54s - loss: 0.1504 - acc: 0.9489 - val_loss: 0.3435 - val_acc: 0.9118\n",
      "\n",
      "Epoch 18/30                                        \n",
      " - 54s - loss: 0.1695 - acc: 0.9459 - val_loss: 0.3411 - val_acc: 0.9030\n",
      "\n",
      "Epoch 19/30                                        \n",
      " - 54s - loss: 0.1575 - acc: 0.9486 - val_loss: 0.4170 - val_acc: 0.9046\n",
      "\n",
      "Epoch 20/30                                        \n",
      " - 54s - loss: 0.1646 - acc: 0.9449 - val_loss: 0.3776 - val_acc: 0.9043\n",
      "\n",
      "Epoch 21/30                                        \n",
      " - 54s - loss: 0.1804 - acc: 0.9452 - val_loss: 0.5554 - val_acc: 0.8907\n",
      "\n",
      "Epoch 22/30                                        \n",
      " - 54s - loss: 0.1828 - acc: 0.9450 - val_loss: 0.4146 - val_acc: 0.9094\n",
      "\n",
      "Epoch 23/30                                        \n",
      " - 54s - loss: 0.1529 - acc: 0.9497 - val_loss: 0.3406 - val_acc: 0.9053\n",
      "\n",
      "Epoch 24/30                                        \n",
      " - 54s - loss: 0.1568 - acc: 0.9478 - val_loss: 0.2781 - val_acc: 0.9131\n",
      "\n",
      "Epoch 25/30                                        \n",
      " - 54s - loss: 0.1643 - acc: 0.9476 - val_loss: 0.4164 - val_acc: 0.9145\n",
      "\n",
      "Epoch 26/30                                        \n",
      " - 54s - loss: 0.1676 - acc: 0.9464 - val_loss: 0.6055 - val_acc: 0.8850\n",
      "\n",
      "Epoch 27/30                                        \n",
      " - 54s - loss: 0.1569 - acc: 0.9484 - val_loss: 0.4221 - val_acc: 0.9080\n",
      "\n",
      "Epoch 28/30                                        \n",
      " - 54s - loss: 0.1547 - acc: 0.9504 - val_loss: 0.3809 - val_acc: 0.9209\n",
      "\n",
      "Epoch 29/30                                        \n",
      " - 61s - loss: 0.1573 - acc: 0.9490 - val_loss: 0.4005 - val_acc: 0.9043\n",
      "\n",
      "Epoch 30/30                                        \n",
      " - 61s - loss: 0.1437 - acc: 0.9516 - val_loss: 0.4309 - val_acc: 0.9036\n",
      "\n",
      "_________________________________________________________________                \n",
      "Layer (type)                 Output Shape              Param #                   \n",
      "=================================================================                \n",
      "lstm_3 (LSTM)                (None, 128, 64)           18944                     \n",
      "_________________________________________________________________                \n",
      "dropout_3 (Dropout)          (None, 128, 64)           0                         \n",
      "_________________________________________________________________                \n",
      "lstm_4 (LSTM)                (None, 64)                33024                     \n",
      "_________________________________________________________________                \n",
      "dropout_4 (Dropout)          (None, 64)                0                         \n",
      "_________________________________________________________________                \n",
      "dense_2 (Dense)              (None, 6)                 390                       \n",
      "=================================================================                \n",
      "Total params: 52,358                                                             \n",
      "Trainable params: 52,358                                                         \n",
      "Non-trainable params: 0                                                          \n",
      "_________________________________________________________________                \n",
      "None                                                                             \n",
      "Train on 7352 samples, validate on 2947 samples                                  \n",
      "Epoch 1/30                                                                       \n",
      " - 66s - loss: 0.9916 - acc: 0.5793 - val_loss: 0.8720 - val_acc: 0.6505         \n",
      "\n",
      "Epoch 2/30                                                                       \n",
      " - 66s - loss: 0.6609 - acc: 0.7254 - val_loss: 0.6846 - val_acc: 0.7316         \n",
      "\n",
      "Epoch 3/30                                                                       \n",
      " - 62s - loss: 0.5587 - acc: 0.7884 - val_loss: 0.6722 - val_acc: 0.7574         \n",
      "\n",
      "Epoch 4/30                                                                       \n",
      " - 62s - loss: 0.3138 - acc: 0.8928 - val_loss: 0.4903 - val_acc: 0.8704         \n",
      "\n",
      "Epoch 5/30                                                                       \n",
      " - 74s - loss: 0.2322 - acc: 0.9172 - val_loss: 0.5107 - val_acc: 0.8629         \n",
      "\n",
      "Epoch 6/30                                                                       \n",
      " - 67s - loss: 0.2005 - acc: 0.9319 - val_loss: 0.4056 - val_acc: 0.8894         \n",
      "\n",
      "Epoch 7/30                                                                       \n",
      " - 62s - loss: 0.1804 - acc: 0.9365 - val_loss: 0.3649 - val_acc: 0.9118         \n",
      "\n",
      "Epoch 8/30                                                                       \n",
      " - 62s - loss: 0.1540 - acc: 0.9412 - val_loss: 0.3643 - val_acc: 0.8975         \n",
      "\n",
      "Epoch 9/30                                                                       \n",
      " - 62s - loss: 0.1663 - acc: 0.9410 - val_loss: 0.3895 - val_acc: 0.9094         \n",
      "\n",
      "Epoch 10/30                                                                      \n",
      " - 62s - loss: 0.1393 - acc: 0.9461 - val_loss: 0.4414 - val_acc: 0.8938         \n",
      "\n",
      "Epoch 11/30                                                                      \n",
      " - 62s - loss: 0.1432 - acc: 0.9474 - val_loss: 0.4058 - val_acc: 0.8985         \n",
      "\n",
      "Epoch 12/30                                                                      \n",
      " - 62s - loss: 0.1409 - acc: 0.9437 - val_loss: 0.3252 - val_acc: 0.9104         \n",
      "\n",
      "Epoch 13/30                                                                      \n",
      " - 62s - loss: 0.1384 - acc: 0.9471 - val_loss: 0.3467 - val_acc: 0.9192         \n",
      "\n",
      "Epoch 14/30                                                                      \n",
      " - 62s - loss: 0.1281 - acc: 0.9491 - val_loss: 0.3217 - val_acc: 0.9125         \n",
      "\n",
      "Epoch 15/30                                                                      \n",
      " - 62s - loss: 0.1332 - acc: 0.9502 - val_loss: 0.3704 - val_acc: 0.9074         \n",
      "\n",
      "Epoch 16/30                                                                      \n",
      " - 61s - loss: 0.1407 - acc: 0.9489 - val_loss: 0.3833 - val_acc: 0.8955         \n",
      "\n",
      "Epoch 17/30                                                                      \n",
      " - 62s - loss: 0.1409 - acc: 0.9472 - val_loss: 0.3830 - val_acc: 0.8890         \n",
      "\n",
      "Epoch 18/30                                                                      \n",
      " - 62s - loss: 0.1328 - acc: 0.9478 - val_loss: 0.4133 - val_acc: 0.9077         \n",
      "\n",
      "Epoch 19/30                                                                      \n",
      " - 62s - loss: 0.1359 - acc: 0.9479 - val_loss: 0.4291 - val_acc: 0.9036         \n",
      "\n",
      "Epoch 20/30                                                                      \n",
      " - 62s - loss: 0.1316 - acc: 0.9484 - val_loss: 0.4164 - val_acc: 0.9091         \n",
      "\n",
      "Epoch 21/30                                                                      \n",
      " - 62s - loss: 0.1283 - acc: 0.9513 - val_loss: 0.3921 - val_acc: 0.9125         \n",
      "\n",
      "Epoch 22/30                                                                      \n",
      " - 62s - loss: 0.1431 - acc: 0.9482 - val_loss: 0.4885 - val_acc: 0.9074         \n",
      "\n",
      "Epoch 23/30                                                                      \n",
      " - 62s - loss: 0.1279 - acc: 0.9540 - val_loss: 0.3809 - val_acc: 0.9087         \n",
      "\n",
      "Epoch 24/30                                                                      \n",
      " - 61s - loss: 0.1179 - acc: 0.9527 - val_loss: 0.4510 - val_acc: 0.9043         \n",
      "\n",
      "Epoch 25/30                                                                      \n",
      " - 62s - loss: 0.1361 - acc: 0.9483 - val_loss: 0.3269 - val_acc: 0.9264         \n",
      "\n",
      "Epoch 26/30                                                                      \n",
      " - 62s - loss: 0.1120 - acc: 0.9540 - val_loss: 0.3994 - val_acc: 0.9033         \n",
      "\n",
      "Epoch 27/30                                                                      \n",
      " - 62s - loss: 0.1322 - acc: 0.9524 - val_loss: 0.4926 - val_acc: 0.9046         \n",
      "\n",
      "Epoch 28/30                                                                      \n",
      " - 61s - loss: 0.1154 - acc: 0.9520 - val_loss: 0.4739 - val_acc: 0.9114         \n",
      "\n",
      "Epoch 29/30                                                                      \n",
      " - 62s - loss: 0.1154 - acc: 0.9548 - val_loss: 0.5415 - val_acc: 0.9091         \n",
      "\n",
      "Epoch 30/30                                                                      \n",
      " - 62s - loss: 0.1187 - acc: 0.9546 - val_loss: 0.5287 - val_acc: 0.8979         \n",
      "\n",
      "_________________________________________________________________                \n",
      "Layer (type)                 Output Shape              Param #                 \n",
      "=================================================================              \n",
      "lstm_5 (LSTM)                (None, 128, 64)           18944                   \n",
      "_________________________________________________________________              \n",
      "dropout_5 (Dropout)          (None, 128, 64)           0                       \n",
      "_________________________________________________________________              \n",
      "lstm_6 (LSTM)                (None, 32)                12416                   \n",
      "_________________________________________________________________              \n",
      "dropout_6 (Dropout)          (None, 32)                0                       \n",
      "_________________________________________________________________              \n",
      "dense_3 (Dense)              (None, 6)                 198                     \n",
      "=================================================================              \n",
      "Total params: 31,558                                                           \n",
      "Trainable params: 31,558                                                       \n",
      "Non-trainable params: 0                                                        \n",
      "_________________________________________________________________              \n",
      "None                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples                                \n",
      "Epoch 1/30                                                                     \n",
      " - 64s - loss: 1.3529 - acc: 0.4335 - val_loss: 1.1770 - val_acc: 0.4506       \n",
      "\n",
      "Epoch 2/30                                                                     \n",
      " - 56s - loss: 1.1150 - acc: 0.5148 - val_loss: 0.9697 - val_acc: 0.5938       \n",
      "\n",
      "Epoch 3/30                                                                       \n",
      " - 56s - loss: 0.9493 - acc: 0.6023 - val_loss: 0.8144 - val_acc: 0.6003         \n",
      "\n",
      "Epoch 4/30                                                                       \n",
      " - 56s - loss: 0.9392 - acc: 0.5913 - val_loss: 0.8347 - val_acc: 0.6040         \n",
      "\n",
      "Epoch 5/30                                                                       \n",
      " - 56s - loss: 0.8170 - acc: 0.6304 - val_loss: 0.7824 - val_acc: 0.6200         \n",
      "\n",
      "Epoch 6/30                                                                       \n",
      " - 56s - loss: 0.7682 - acc: 0.6348 - val_loss: 0.8184 - val_acc: 0.6064         \n",
      "\n",
      "Epoch 7/30                                                                       \n",
      " - 56s - loss: 0.7729 - acc: 0.6421 - val_loss: 0.7878 - val_acc: 0.6172         \n",
      "\n",
      "Epoch 8/30                                                                       \n",
      " - 56s - loss: 0.7577 - acc: 0.6420 - val_loss: 0.9185 - val_acc: 0.5948         \n",
      "\n",
      "Epoch 9/30                                                                       \n",
      " - 55s - loss: 0.7370 - acc: 0.6415 - val_loss: 0.7116 - val_acc: 0.6172         \n",
      "\n",
      "Epoch 10/30                                                                      \n",
      " - 55s - loss: 0.7343 - acc: 0.6480 - val_loss: 0.7171 - val_acc: 0.6200         \n",
      "\n",
      "Epoch 11/30                                                                      \n",
      " - 61s - loss: 0.6960 - acc: 0.6772 - val_loss: 0.6793 - val_acc: 0.6254         \n",
      "\n",
      "Epoch 12/30                                                                      \n",
      " - 57s - loss: 0.6638 - acc: 0.7142 - val_loss: 0.6380 - val_acc: 0.7234         \n",
      "\n",
      "Epoch 13/30                                                                      \n",
      " - 56s - loss: 0.6055 - acc: 0.7520 - val_loss: 0.5734 - val_acc: 0.7431         \n",
      "\n",
      "Epoch 14/30                                                                      \n",
      " - 56s - loss: 0.5477 - acc: 0.7590 - val_loss: 0.4681 - val_acc: 0.7665         \n",
      "\n",
      "Epoch 15/30                                                                      \n",
      " - 56s - loss: 0.5308 - acc: 0.7769 - val_loss: 0.5356 - val_acc: 0.8371         \n",
      "\n",
      "Epoch 16/30                                                                      \n",
      " - 68s - loss: 0.4842 - acc: 0.8097 - val_loss: 0.5060 - val_acc: 0.8778         \n",
      "\n",
      "Epoch 17/30                                                                      \n",
      " - 58s - loss: 0.4489 - acc: 0.8478 - val_loss: 0.4826 - val_acc: 0.8802         \n",
      "\n",
      "Epoch 18/30                                                                      \n",
      " - 56s - loss: 0.4155 - acc: 0.8672 - val_loss: 0.5634 - val_acc: 0.8823         \n",
      "\n",
      "Epoch 19/30                                                                      \n",
      " - 56s - loss: 0.3703 - acc: 0.8875 - val_loss: 0.4773 - val_acc: 0.8799         \n",
      "\n",
      "Epoch 20/30                                                                      \n",
      " - 56s - loss: 0.3632 - acc: 0.8876 - val_loss: 0.2716 - val_acc: 0.9141         \n",
      "\n",
      "Epoch 21/30                                                                      \n",
      " - 56s - loss: 0.3319 - acc: 0.8993 - val_loss: 0.5872 - val_acc: 0.8748         \n",
      "\n",
      "Epoch 22/30                                                                      \n",
      " - 56s - loss: 0.3055 - acc: 0.9076 - val_loss: 0.5115 - val_acc: 0.8928         \n",
      "\n",
      "Epoch 23/30                                                                      \n",
      " - 56s - loss: 0.3275 - acc: 0.9049 - val_loss: 0.3554 - val_acc: 0.8839         \n",
      "\n",
      "Epoch 24/30                                                                      \n",
      " - 56s - loss: 0.3300 - acc: 0.8999 - val_loss: 0.4766 - val_acc: 0.8863         \n",
      "\n",
      "Epoch 25/30                                                                      \n",
      " - 56s - loss: 0.2933 - acc: 0.9120 - val_loss: 0.4058 - val_acc: 0.9138         \n",
      "\n",
      "Epoch 26/30                                                                      \n",
      " - 56s - loss: 0.2925 - acc: 0.9124 - val_loss: 0.4290 - val_acc: 0.8968         \n",
      "\n",
      "Epoch 27/30                                                                      \n",
      " - 56s - loss: 0.3199 - acc: 0.9079 - val_loss: 0.4157 - val_acc: 0.9108         \n",
      "\n",
      "Epoch 28/30                                                                      \n",
      " - 56s - loss: nan - acc: 0.5215 - val_loss: nan - val_acc: 0.1683               \n",
      "\n",
      "Epoch 29/30                                                                      \n",
      " - 55s - loss: nan - acc: 0.1668 - val_loss: nan - val_acc: 0.1683               \n",
      "\n",
      "Epoch 30/30                                                                      \n",
      " - 56s - loss: nan - acc: 0.1668 - val_loss: nan - val_acc: 0.1683               \n",
      "\n",
      "_________________________________________________________________                \n",
      "Layer (type)                 Output Shape              Param #                   \n",
      "=================================================================                \n",
      "lstm_7 (LSTM)                (None, 128, 64)           18944                     \n",
      "_________________________________________________________________                \n",
      "dropout_7 (Dropout)          (None, 128, 64)           0                         \n",
      "_________________________________________________________________                \n",
      "lstm_8 (LSTM)                (None, 32)                12416                     \n",
      "_________________________________________________________________                \n",
      "dropout_8 (Dropout)          (None, 32)                0                         \n",
      "_________________________________________________________________                \n",
      "dense_4 (Dense)              (None, 6)                 198                       \n",
      "=================================================================                \n",
      "Total params: 31,558                                                             \n",
      "Trainable params: 31,558                                                         \n",
      "Non-trainable params: 0                                                          \n",
      "_________________________________________________________________                \n",
      "None                                                                             \n",
      "Train on 7352 samples, validate on 2947 samples                                  \n",
      "Epoch 1/30                                                                       \n",
      " - 58s - loss: 1.2752 - acc: 0.4599 - val_loss: 1.3730 - val_acc: 0.4170         \n",
      "\n",
      "Epoch 2/30                                                                       \n",
      " - 58s - loss: 1.0810 - acc: 0.5117 - val_loss: 1.0145 - val_acc: 0.5433         \n",
      "\n",
      "Epoch 3/30                                                                       \n",
      " - 56s - loss: 0.8354 - acc: 0.6215 - val_loss: 0.8804 - val_acc: 0.6037         \n",
      "\n",
      "Epoch 4/30                                                                       \n",
      " - 56s - loss: 0.7491 - acc: 0.6470 - val_loss: 0.8693 - val_acc: 0.5959         \n",
      "\n",
      "Epoch 5/30                                                                       \n",
      " - 69s - loss: 0.6308 - acc: 0.7397 - val_loss: 0.5886 - val_acc: 0.8147         \n",
      "\n",
      "Epoch 6/30                                                                       \n",
      " - 61s - loss: 0.4636 - acc: 0.8473 - val_loss: 0.4611 - val_acc: 0.8558         \n",
      "\n",
      "Epoch 7/30                                                                       \n",
      " - 57s - loss: 0.3468 - acc: 0.8998 - val_loss: 0.3941 - val_acc: 0.8734         \n",
      "\n",
      "Epoch 8/30                                                                       \n",
      " - 56s - loss: 0.2703 - acc: 0.9212 - val_loss: 0.3566 - val_acc: 0.8880         \n",
      "\n",
      "Epoch 9/30                                                                       \n",
      " - 56s - loss: 0.2458 - acc: 0.9226 - val_loss: 0.4413 - val_acc: 0.8914         \n",
      "\n",
      "Epoch 10/30                                                                      \n",
      " - 55s - loss: 0.2225 - acc: 0.9335 - val_loss: 0.6937 - val_acc: 0.8561         \n",
      "\n",
      "Epoch 11/30                                                                      \n",
      " - 56s - loss: 0.2051 - acc: 0.9335 - val_loss: 0.3882 - val_acc: 0.8968         \n",
      "\n",
      "Epoch 12/30                                                                      \n",
      " - 56s - loss: 0.1787 - acc: 0.9404 - val_loss: 0.4525 - val_acc: 0.9030         \n",
      "\n",
      "Epoch 13/30                                                                      \n",
      " - 56s - loss: 0.1790 - acc: 0.9433 - val_loss: 0.3438 - val_acc: 0.9013         \n",
      "\n",
      "Epoch 14/30                                                                      \n",
      " - 56s - loss: 0.1593 - acc: 0.9478 - val_loss: 0.3606 - val_acc: 0.9121         \n",
      "\n",
      "Epoch 15/30                                                                      \n",
      " - 62s - loss: 0.1641 - acc: 0.9465 - val_loss: 0.2942 - val_acc: 0.9165         \n",
      "\n",
      "Epoch 16/30                                                                      \n",
      " - 55s - loss: 0.1586 - acc: 0.9474 - val_loss: 0.3616 - val_acc: 0.9108         \n",
      "\n",
      "Epoch 17/30                                                                      \n",
      " - 53s - loss: 0.1548 - acc: 0.9468 - val_loss: 0.2793 - val_acc: 0.9057         \n",
      "\n",
      "Epoch 18/30                                                                      \n",
      " - 58s - loss: 0.1704 - acc: 0.9384 - val_loss: 0.4071 - val_acc: 0.9169         \n",
      "\n",
      "Epoch 19/30                                                                      \n",
      " - 54s - loss: 0.1673 - acc: 0.9416 - val_loss: 0.3712 - val_acc: 0.9006         \n",
      "\n",
      "Epoch 20/30                                                                      \n",
      " - 54s - loss: 0.1497 - acc: 0.9472 - val_loss: 0.3156 - val_acc: 0.9070         \n",
      "\n",
      "Epoch 21/30                                                                      \n",
      " - 54s - loss: 0.1663 - acc: 0.9425 - val_loss: 0.3463 - val_acc: 0.9101         \n",
      "\n",
      "Epoch 22/30                                                                      \n",
      " - 54s - loss: 0.1522 - acc: 0.9478 - val_loss: 0.3250 - val_acc: 0.9138         \n",
      "\n",
      "Epoch 23/30                                                                      \n",
      " - 54s - loss: 0.1453 - acc: 0.9504 - val_loss: 0.4112 - val_acc: 0.9148         \n",
      "\n",
      "Epoch 24/30                                                                      \n",
      " - 54s - loss: 0.1401 - acc: 0.9505 - val_loss: 0.3780 - val_acc: 0.9128         \n",
      "\n",
      "Epoch 25/30                                                                      \n",
      " - 54s - loss: 0.1399 - acc: 0.9504 - val_loss: 0.3477 - val_acc: 0.9077         \n",
      "\n",
      "Epoch 26/30                                                                      \n",
      " - 55s - loss: 0.1380 - acc: 0.9484 - val_loss: 0.4284 - val_acc: 0.9118         \n",
      "\n",
      "Epoch 27/30                                                                      \n",
      " - 55s - loss: 0.1452 - acc: 0.9516 - val_loss: 0.3416 - val_acc: 0.9097         \n",
      "\n",
      "Epoch 28/30                                                                      \n",
      " - 55s - loss: 0.1477 - acc: 0.9499 - val_loss: 0.4400 - val_acc: 0.9040         \n",
      "\n",
      "Epoch 29/30                                                                      \n",
      " - 56s - loss: 0.1476 - acc: 0.9494 - val_loss: 0.4360 - val_acc: 0.9138         \n",
      "\n",
      "Epoch 30/30                                                                      \n",
      " - 55s - loss: 0.1419 - acc: 0.9472 - val_loss: 0.3898 - val_acc: 0.9192         \n",
      "\n",
      "100%|██████████| 4/4 [1:55:21<00:00, 1706.09s/it, best loss: -0.9263657957244655]\n",
      "2947/2947 [==============================] - 3s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "best_run, best_model = optim.minimize(model=create_model, data=data, algo=tpe.suggest, max_evals=4, trials=Trials(), notebook_name = \"HAR_LSTM\")\n",
    "score = best_model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "|      Accuracy      |\n",
      "---------------------\n",
      "89.79%\n",
      "\n",
      "----------------------------------\n",
      "|      Best Hyper-Parameters      |\n",
      "----------------------------------\n",
      "{'Dropout': 0.42522861686845626, 'Dropout_1': 0.23316134447477344, 'LSTM': 0}\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 128, 64)           18944     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 52,358\n",
      "Trainable params: 52,358\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('---------------------')\n",
    "print('|      Accuracy      |')\n",
    "print('---------------------')\n",
    "acc = np.round((score[1]*100), 2)\n",
    "print(str(acc)+\"%\\n\")\n",
    "    \n",
    "print('----------------------------------')\n",
    "print('|      Best Hyper-Parameters      |')\n",
    "print('----------------------------------')\n",
    "print(best_run)\n",
    "print(best_model.summary())\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "true_values = [np.argmax(i)+1 for i in Y_test]\n",
    "predicted_prob = best_model.predict(X_test)\n",
    "predicted_values = [np.argmax(i)+1 for i in predicted_prob]\n",
    "\n",
    "\n",
    "label = [\"WALKING\", \"WALKING_UPSTAIRS\", \"WALKING_DOWNSTAIRS\", \"SITTING\", \"STANDING\", \"LYING\"]\n",
    "frame_confusion = pd.DataFrame(confusion_matrix(true_values, predicted_values), index = label, columns = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(frame_confusion, annot = True, fmt=\"d\", cmap=\"YlGnBu\", linewidths=.5)\n",
    "plt.title(\"Test confusion matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 126, 32)           896       \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 124, 64)           6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 62, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 62, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3968)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               508032    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 515,910\n",
      "Trainable params: 515,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(Conv1D(32, kernel_size=(3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(timesteps, input_dim)))\n",
    "model.add(Conv1D(64, (3), activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 5s 734us/step - loss: 0.4459 - acc: 0.8256 - val_loss: 0.6001 - val_acc: 0.8504\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 5s 697us/step - loss: 0.1729 - acc: 0.9335 - val_loss: 0.5595 - val_acc: 0.8809\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 7s 931us/step - loss: 0.1384 - acc: 0.9463 - val_loss: 0.5038 - val_acc: 0.8918\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 5s 744us/step - loss: 0.1313 - acc: 0.9479 - val_loss: 0.5545 - val_acc: 0.9043\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 9s 1ms/step - loss: 0.1300 - acc: 0.9487 - val_loss: 0.5064 - val_acc: 0.8945\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 6s 799us/step - loss: 0.1251 - acc: 0.9501 - val_loss: 0.5968 - val_acc: 0.9019\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 5s 669us/step - loss: 0.1130 - acc: 0.9548 - val_loss: 0.6791 - val_acc: 0.8904\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 6s 864us/step - loss: 0.1288 - acc: 0.9559 - val_loss: 0.5973 - val_acc: 0.9019\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 6s 791us/step - loss: 0.1064 - acc: 0.9557 - val_loss: 0.5702 - val_acc: 0.9138\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 6s 772us/step - loss: 0.1134 - acc: 0.9600 - val_loss: 0.7175 - val_acc: 0.8775\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 7s 889us/step - loss: 0.1101 - acc: 0.9593 - val_loss: 0.5762 - val_acc: 0.9111\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 6s 814us/step - loss: 0.1041 - acc: 0.9612 - val_loss: 0.6469 - val_acc: 0.8968\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 6s 811us/step - loss: 0.1049 - acc: 0.9614 - val_loss: 0.8040 - val_acc: 0.8656\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 6s 809us/step - loss: 0.1071 - acc: 0.9606 - val_loss: 0.7094 - val_acc: 0.8867\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 6s 812us/step - loss: 0.1341 - acc: 0.9580 - val_loss: 0.6005 - val_acc: 0.9077\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 6s 806us/step - loss: 0.1160 - acc: 0.9597 - val_loss: 0.7558 - val_acc: 0.8962\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 6s 810us/step - loss: 0.1091 - acc: 0.9600 - val_loss: 0.7779 - val_acc: 0.8962\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 6s 808us/step - loss: 0.1200 - acc: 0.9601 - val_loss: 0.7154 - val_acc: 0.8938\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 6s 810us/step - loss: 0.1220 - acc: 0.9597 - val_loss: 0.8599 - val_acc: 0.8795\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 6s 804us/step - loss: 0.1163 - acc: 0.9584 - val_loss: 1.0634 - val_acc: 0.8809\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 6s 808us/step - loss: 0.1389 - acc: 0.9578 - val_loss: 0.8886 - val_acc: 0.8989\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 6s 804us/step - loss: 0.1366 - acc: 0.9612 - val_loss: 0.8346 - val_acc: 0.9050\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 6s 803us/step - loss: 0.1625 - acc: 0.9596 - val_loss: 1.0125 - val_acc: 0.8887\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 6s 805us/step - loss: 0.1763 - acc: 0.9544 - val_loss: 1.1151 - val_acc: 0.8700\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 6s 806us/step - loss: 0.1820 - acc: 0.9542 - val_loss: 0.9204 - val_acc: 0.8924\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 6s 810us/step - loss: 0.2264 - acc: 0.9546 - val_loss: 1.1435 - val_acc: 0.8704\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 6s 804us/step - loss: 0.2382 - acc: 0.9548 - val_loss: 1.4356 - val_acc: 0.8663\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 6s 804us/step - loss: 0.2521 - acc: 0.9518 - val_loss: 1.0517 - val_acc: 0.8836\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 6s 804us/step - loss: 0.2617 - acc: 0.9520 - val_loss: 0.9957 - val_acc: 0.8846\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 6s 807us/step - loss: 0.4054 - acc: 0.9450 - val_loss: 1.7297 - val_acc: 0.8409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11e2ac5f8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 536        0         0        0                   0   \n",
      "SITTING                  0      383       105        0                   0   \n",
      "STANDING                 1       64       461        2                   0   \n",
      "WALKING                  0        0         0      490                   4   \n",
      "WALKING_DOWNSTAIRS       0        0         0       95                 295   \n",
      "WALKING_UPSTAIRS         0        0         0       37                  25   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             1  \n",
      "SITTING                            3  \n",
      "STANDING                           4  \n",
      "WALKING                            2  \n",
      "WALKING_DOWNSTAIRS                30  \n",
      "WALKING_UPSTAIRS                 409  \n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 2s 800us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.9993040630948475, 0.8734306073973532]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 126, 64)           1792      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 63, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 61, 64)            12352     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 61, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3904)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 23430     \n",
      "=================================================================\n",
      "Total params: 37,574\n",
      "Trainable params: 37,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(Conv1D(64, kernel_size=(3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(timesteps, input_dim)))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Conv1D(64, (3), activation='relu'))\n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 4s 527us/step - loss: 0.3983 - acc: 0.8419 - val_loss: 0.5101 - val_acc: 0.8711\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 4s 488us/step - loss: 0.1480 - acc: 0.9419 - val_loss: 0.5742 - val_acc: 0.8911\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 4s 490us/step - loss: 0.1239 - acc: 0.9475 - val_loss: 0.4594 - val_acc: 0.8955\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 4s 490us/step - loss: 0.1093 - acc: 0.9554 - val_loss: 0.5108 - val_acc: 0.9111\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 4s 490us/step - loss: 0.0999 - acc: 0.9570 - val_loss: 0.5746 - val_acc: 0.8948\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 4s 491us/step - loss: 0.0921 - acc: 0.9588 - val_loss: 0.5230 - val_acc: 0.8996\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 4s 493us/step - loss: 0.0870 - acc: 0.9634 - val_loss: 0.4725 - val_acc: 0.9175\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 4s 494us/step - loss: 0.0836 - acc: 0.9630 - val_loss: 0.6286 - val_acc: 0.9145\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 4s 495us/step - loss: 0.0867 - acc: 0.9638 - val_loss: 0.5641 - val_acc: 0.9074\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 4s 497us/step - loss: 0.0788 - acc: 0.9687 - val_loss: 0.5927 - val_acc: 0.9053\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 4s 497us/step - loss: 0.0779 - acc: 0.9674 - val_loss: 0.6771 - val_acc: 0.8968\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 4s 498us/step - loss: 0.0856 - acc: 0.9687 - val_loss: 0.5735 - val_acc: 0.9206\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 4s 500us/step - loss: 0.0822 - acc: 0.9683 - val_loss: 0.5932 - val_acc: 0.9101\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 4s 500us/step - loss: 0.0732 - acc: 0.9733 - val_loss: 0.7964 - val_acc: 0.8806\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 4s 500us/step - loss: 0.0742 - acc: 0.9732 - val_loss: 0.6334 - val_acc: 0.9135\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 4s 501us/step - loss: 0.0721 - acc: 0.9744 - val_loss: 0.5987 - val_acc: 0.9074\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 4s 504us/step - loss: 0.0716 - acc: 0.9770 - val_loss: 0.5897 - val_acc: 0.9111\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 4s 504us/step - loss: 0.0702 - acc: 0.9757 - val_loss: 0.7060 - val_acc: 0.9033\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 4s 502us/step - loss: 0.0680 - acc: 0.9761 - val_loss: 0.6298 - val_acc: 0.8931\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 4s 506us/step - loss: 0.0675 - acc: 0.9762 - val_loss: 0.6838 - val_acc: 0.9087\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 4s 505us/step - loss: 0.0766 - acc: 0.9773 - val_loss: 0.6224 - val_acc: 0.9111\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 4s 502us/step - loss: 0.0682 - acc: 0.9784 - val_loss: 0.6149 - val_acc: 0.9050\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 4s 503us/step - loss: 0.0702 - acc: 0.9778 - val_loss: 0.5445 - val_acc: 0.9220\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 4s 503us/step - loss: 0.0630 - acc: 0.9801 - val_loss: 0.5698 - val_acc: 0.9287\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 4s 503us/step - loss: 0.0653 - acc: 0.9799 - val_loss: 0.6066 - val_acc: 0.9172\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 4s 505us/step - loss: 0.0545 - acc: 0.9814 - val_loss: 0.6469 - val_acc: 0.9243\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 4s 503us/step - loss: 0.0609 - acc: 0.9810 - val_loss: 0.7518 - val_acc: 0.9063\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 4s 504us/step - loss: 0.0559 - acc: 0.9818 - val_loss: 0.7213 - val_acc: 0.9118\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 4s 503us/step - loss: 0.0557 - acc: 0.9810 - val_loss: 0.6295 - val_acc: 0.9226\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 4s 504us/step - loss: 0.0585 - acc: 0.9812 - val_loss: 0.7338 - val_acc: 0.9057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12bbdd3c8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred                LAYING  SITTING  STANDING  WALKING  WALKING_DOWNSTAIRS  \\\n",
      "True                                                                         \n",
      "LAYING                 536        0         0        0                   0   \n",
      "SITTING                  1      435        47        1                   0   \n",
      "STANDING                 0      107       417        3                   1   \n",
      "WALKING                  0        0         0      453                  42   \n",
      "WALKING_DOWNSTAIRS       0        0         0        0                 420   \n",
      "WALKING_UPSTAIRS         0        0         0       16                  47   \n",
      "\n",
      "Pred                WALKING_UPSTAIRS  \n",
      "True                                  \n",
      "LAYING                             1  \n",
      "SITTING                            7  \n",
      "STANDING                           4  \n",
      "WALKING                            1  \n",
      "WALKING_DOWNSTAIRS                 0  \n",
      "WALKING_UPSTAIRS                 408  \n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2947/2947 [==============================] - 0s 115us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7338126605104306, 0.9056667797760435]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_61 (TimeDis (None, None, 30, 128)     3584      \n",
      "_________________________________________________________________\n",
      "time_distributed_62 (TimeDis (None, None, 15, 128)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_63 (TimeDis (None, None, 13, 64)      24640     \n",
      "_________________________________________________________________\n",
      "time_distributed_64 (TimeDis (None, None, 13, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_65 (TimeDis (None, None, 6, 64)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_66 (TimeDis (None, None, 384)         0         \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 128)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               12900     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 304,386\n",
      "Trainable params: 304,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(TimeDistributed(Conv1D(filters=128, kernel_size=3, activation='relu'), input_shape=(None,32,input_dim)))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "model.add(TimeDistributed(Dropout(0.8)))\n",
    "model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.8))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7352 samples, validate on 2947 samples\n",
      "Epoch 1/30\n",
      "7352/7352 [==============================] - 16s 2ms/step - loss: 0.6793 - acc: 0.7058 - val_loss: 0.5768 - val_acc: 0.7696\n",
      "Epoch 2/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.2548 - acc: 0.9089 - val_loss: 0.3187 - val_acc: 0.8880\n",
      "Epoch 3/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.1646 - acc: 0.9369 - val_loss: 0.3886 - val_acc: 0.8789\n",
      "Epoch 4/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.1519 - acc: 0.9407 - val_loss: 0.3131 - val_acc: 0.8785\n",
      "Epoch 5/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.1476 - acc: 0.9402 - val_loss: 0.3329 - val_acc: 0.9033\n",
      "Epoch 6/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.1232 - acc: 0.9484 - val_loss: 0.2871 - val_acc: 0.9101\n",
      "Epoch 7/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.1487 - acc: 0.9404 - val_loss: 0.3046 - val_acc: 0.9080\n",
      "Epoch 8/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.1235 - acc: 0.9484 - val_loss: 0.4001 - val_acc: 0.8846\n",
      "Epoch 9/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.1124 - acc: 0.9550 - val_loss: 0.2971 - val_acc: 0.8985\n",
      "Epoch 10/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.1513 - acc: 0.9487 - val_loss: 0.2743 - val_acc: 0.9155\n",
      "Epoch 11/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.1231 - acc: 0.9508 - val_loss: 0.3198 - val_acc: 0.9101\n",
      "Epoch 12/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.1229 - acc: 0.9516 - val_loss: 0.2866 - val_acc: 0.9158\n",
      "Epoch 13/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.1161 - acc: 0.9543 - val_loss: 0.2893 - val_acc: 0.9009\n",
      "Epoch 14/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.1070 - acc: 0.9543 - val_loss: 0.4145 - val_acc: 0.9030\n",
      "Epoch 15/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.1068 - acc: 0.9555 - val_loss: 0.4424 - val_acc: 0.9074\n",
      "Epoch 16/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.1029 - acc: 0.9573 - val_loss: 0.5188 - val_acc: 0.8985\n",
      "Epoch 17/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.0955 - acc: 0.9600 - val_loss: 0.3972 - val_acc: 0.9084\n",
      "Epoch 18/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.1159 - acc: 0.9546 - val_loss: 0.2953 - val_acc: 0.9162\n",
      "Epoch 19/30\n",
      "7352/7352 [==============================] - 14s 2ms/step - loss: 0.1113 - acc: 0.9559 - val_loss: 0.4626 - val_acc: 0.9131\n",
      "Epoch 20/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.0929 - acc: 0.9601 - val_loss: 0.5852 - val_acc: 0.9067\n",
      "Epoch 21/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.0910 - acc: 0.9607 - val_loss: 0.5250 - val_acc: 0.9104\n",
      "Epoch 22/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.0955 - acc: 0.9618 - val_loss: 0.5021 - val_acc: 0.9104\n",
      "Epoch 23/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.1269 - acc: 0.9558 - val_loss: 0.3983 - val_acc: 0.9067\n",
      "Epoch 24/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.0924 - acc: 0.9610 - val_loss: 0.5166 - val_acc: 0.9196\n",
      "Epoch 25/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.0884 - acc: 0.9615 - val_loss: 0.5698 - val_acc: 0.9097\n",
      "Epoch 26/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.0829 - acc: 0.9633 - val_loss: 0.6748 - val_acc: 0.9101\n",
      "Epoch 27/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.0785 - acc: 0.9641 - val_loss: 0.6022 - val_acc: 0.9030\n",
      "Epoch 28/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.0896 - acc: 0.9610 - val_loss: 0.7464 - val_acc: 0.9046\n",
      "Epoch 29/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.0808 - acc: 0.9645 - val_loss: 0.5340 - val_acc: 0.9192\n",
      "Epoch 30/30\n",
      "7352/7352 [==============================] - 15s 2ms/step - loss: 0.0856 - acc: 0.9634 - val_loss: 0.5917 - val_acc: 0.8992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13f5280f0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(testX, Y_test),\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN + Test Sharpening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "dir_path = './UCI HAR Dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_x(train_or_test):\n",
    "    global dir_path\n",
    "    if train_or_test is \"train\":\n",
    "        x_path = dir_path + 'train/X_train.txt'\n",
    "    elif train_or_test is \"test\":\n",
    "        x_path = dir_path + 'test/X_test.txt'\n",
    "\n",
    "    with open(x_path) as f:\n",
    "        container = f.readlines()\n",
    "\n",
    "    result = []\n",
    "    for line in container:\n",
    "        tmp1 = line.strip()\n",
    "        tmp2 = tmp1.replace('  ', ' ')     # removes inconsistent blank spaces\n",
    "        tmp_ary = list(map(float, tmp2.split(' ')))\n",
    "        result.append(tmp_ary)\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_y(train_or_test):\n",
    "    global dir_path\n",
    "    if train_or_test is \"train\":\n",
    "        y_path = dir_path + 'train/y_train.txt'\n",
    "    elif train_or_test is \"test\":\n",
    "        y_path = dir_path + 'test/y_test.txt'\n",
    "\n",
    "    with open(y_path) as f:\n",
    "        container = f.readlines()\n",
    "\n",
    "    result = []\n",
    "    for line in container:\n",
    "        num_str = line.strip()\n",
    "        result.append(int(num_str))\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpen(x_test, sigma, alpha):\n",
    "    r = x_test.shape[0]\n",
    "    c = x_test.shape[1]\n",
    "    container = np.empty((r, c))\n",
    "    i = 0\n",
    "\n",
    "    for row in x_test:\n",
    "        test = np.array([row])\n",
    "        blurred = ndimage.gaussian_filter(test, sigma)\n",
    "        sharpened = test + alpha * (test - blurred)\n",
    "        container[i] = sharpened\n",
    "        i = i + 1\n",
    "    return container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from numpy.random import seed\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = load_x(\"train\")   # at this stage, the data includes both dynamic and static HAR data\n",
    "y_train_all = load_y(\"train\")\n",
    "\n",
    "X_test_all = load_x(\"test\")\n",
    "y_test_all = load_y(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7352, 561)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_1 = np.where(y_train_all == 4)[0]\n",
    "static_2 = np.where(y_train_all == 5)[0]\n",
    "static_3 = np.where(y_train_all == 6)[0]\n",
    "static = np.concatenate([static_1, static_2, static_3])\n",
    "static_list = static.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = random.random()\n",
    "random.shuffle(static_list, lambda: r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "static = np.array(static_list)\n",
    "\n",
    "X_train = X_train_all[static]\n",
    "y_train = y_train_all[static]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train  = y_train - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+++ DATA STATISTICS +++\n",
      "\n",
      "train_static shape:  (4067, 561)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n+++ DATA STATISTICS +++\\n\")\n",
    "print(\"train_static shape: \", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_1 = np.where(y_test_all == 4)[0]\n",
    "static_2 = np.where(y_test_all == 5)[0]\n",
    "static_3 = np.where(y_test_all == 6)[0]\n",
    "static = np.concatenate([static_1, static_2, static_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test_all[static]\n",
    "y_test = y_test_all[static]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test  = y_test - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_static shape:  (1560, 561)\n"
     ]
    }
   ],
   "source": [
    "print(\"test_static shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to one hot encoding vector\n",
    "y_train_static_oh = np.eye(n_classes)[y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "seed(2017)\n",
    "model = Sequential()\n",
    "model.add(Conv1D(30, 3, input_shape=(561, 1), activation='relu'))\n",
    "model.add(Conv1D(50, 3, activation='relu'))\n",
    "model.add(Conv1D(100, 3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='mean_squared_error', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 559, 30)           120       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 557, 50)           4550      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 555, 100)          15100     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 55500)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 166503    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 186,273\n",
      "Trainable params: 186,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir = 'model/'\n",
    "if not os.path.exists(new_dir):\n",
    "    os.makedirs(new_dir)\n",
    "fpath = new_dir + 'weights.{epoch:02d}-{val_acc:.2f}.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_cb = ModelCheckpoint(fpath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3253 samples, validate on 814 samples\n",
      "Epoch 1/100\n",
      " - 5s - loss: 0.3092 - acc: 0.4270 - val_loss: 0.1336 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13363, saving model to model/weights.01-0.93.hdf5\n",
      "Epoch 2/100\n",
      " - 5s - loss: 0.2576 - acc: 0.5192 - val_loss: 0.0739 - val_acc: 0.9570\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13363 to 0.07388, saving model to model/weights.02-0.96.hdf5\n",
      "Epoch 3/100\n",
      " - 4s - loss: 0.2457 - acc: 0.5327 - val_loss: 0.0743 - val_acc: 0.9595\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.07388\n",
      "Epoch 4/100\n",
      " - 5s - loss: 0.2502 - acc: 0.5143 - val_loss: 0.0770 - val_acc: 0.9582\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.07388\n",
      "Epoch 5/100\n",
      " - 5s - loss: 0.2428 - acc: 0.5337 - val_loss: 0.0693 - val_acc: 0.9656\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.07388 to 0.06925, saving model to model/weights.05-0.97.hdf5\n",
      "Epoch 6/100\n",
      " - 5s - loss: 0.2376 - acc: 0.5413 - val_loss: 0.0626 - val_acc: 0.9595\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.06925 to 0.06256, saving model to model/weights.06-0.96.hdf5\n",
      "Epoch 7/100\n",
      " - 5s - loss: 0.2357 - acc: 0.5444 - val_loss: 0.0734 - val_acc: 0.9631\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06256\n",
      "Epoch 8/100\n",
      " - 5s - loss: 0.2317 - acc: 0.5503 - val_loss: 0.0701 - val_acc: 0.9656\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06256\n",
      "Epoch 9/100\n",
      " - 5s - loss: 0.2372 - acc: 0.5337 - val_loss: 0.0664 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.06256\n",
      "Epoch 10/100\n",
      " - 4s - loss: 0.2354 - acc: 0.5420 - val_loss: 0.0748 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.06256\n",
      "Epoch 11/100\n",
      " - 4s - loss: 0.2364 - acc: 0.5392 - val_loss: 0.0594 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.06256 to 0.05940, saving model to model/weights.11-0.97.hdf5\n",
      "Epoch 12/100\n",
      " - 4s - loss: 0.2357 - acc: 0.5346 - val_loss: 0.0600 - val_acc: 0.9656\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.05940\n",
      "Epoch 13/100\n",
      " - 5s - loss: 0.2392 - acc: 0.5263 - val_loss: 0.0662 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.05940\n",
      "Epoch 14/100\n",
      " - 5s - loss: 0.2328 - acc: 0.5334 - val_loss: 0.0635 - val_acc: 0.9607\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.05940\n",
      "Epoch 15/100\n",
      " - 5s - loss: 0.2338 - acc: 0.5395 - val_loss: 0.0668 - val_acc: 0.9693\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.05940\n",
      "Epoch 16/100\n",
      " - 5s - loss: 0.2289 - acc: 0.5512 - val_loss: 0.0652 - val_acc: 0.9631\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.05940\n",
      "Epoch 17/100\n",
      " - 4s - loss: 0.2278 - acc: 0.5629 - val_loss: 0.0767 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.05940\n",
      "Epoch 18/100\n",
      " - 4s - loss: 0.2300 - acc: 0.5496 - val_loss: 0.0707 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.05940\n",
      "Epoch 19/100\n",
      " - 5s - loss: 0.2347 - acc: 0.5361 - val_loss: 0.0657 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.05940\n",
      "Epoch 20/100\n",
      " - 5s - loss: 0.2300 - acc: 0.5493 - val_loss: 0.0626 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.05940\n",
      "Epoch 21/100\n",
      " - 5s - loss: 0.2302 - acc: 0.5457 - val_loss: 0.0690 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.05940\n",
      "Epoch 22/100\n",
      " - 5s - loss: 0.2319 - acc: 0.5377 - val_loss: 0.0667 - val_acc: 0.9631\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.05940\n",
      "Epoch 23/100\n",
      " - 5s - loss: 0.2292 - acc: 0.5447 - val_loss: 0.0656 - val_acc: 0.9607\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.05940\n",
      "Epoch 24/100\n",
      " - 4s - loss: 0.2293 - acc: 0.5413 - val_loss: 0.0678 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.05940\n",
      "Epoch 25/100\n",
      " - 5s - loss: 0.2337 - acc: 0.5383 - val_loss: 0.0677 - val_acc: 0.9656\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.05940\n",
      "Epoch 26/100\n",
      " - 5s - loss: 0.2242 - acc: 0.5601 - val_loss: 0.0706 - val_acc: 0.9631\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.05940\n",
      "Epoch 27/100\n",
      " - 5s - loss: 0.2297 - acc: 0.5478 - val_loss: 0.0732 - val_acc: 0.9693\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.05940\n",
      "Epoch 28/100\n",
      " - 5s - loss: 0.2355 - acc: 0.5300 - val_loss: 0.0651 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.05940\n",
      "Epoch 29/100\n",
      " - 5s - loss: 0.2331 - acc: 0.5367 - val_loss: 0.0659 - val_acc: 0.9681\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.05940\n",
      "Epoch 30/100\n",
      " - 5s - loss: 0.2361 - acc: 0.5201 - val_loss: 0.0697 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.05940\n",
      "Epoch 31/100\n",
      " - 5s - loss: 0.2354 - acc: 0.5306 - val_loss: 0.0646 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.05940\n",
      "Epoch 32/100\n",
      " - 5s - loss: 0.2259 - acc: 0.5601 - val_loss: 0.0688 - val_acc: 0.9631\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.05940\n",
      "Epoch 33/100\n",
      " - 4s - loss: 0.2286 - acc: 0.5444 - val_loss: 0.0729 - val_acc: 0.9656\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.05940\n",
      "Epoch 34/100\n",
      " - 6s - loss: 0.2312 - acc: 0.5460 - val_loss: 0.0651 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.05940\n",
      "Epoch 35/100\n",
      " - 5s - loss: 0.2299 - acc: 0.5450 - val_loss: 0.0728 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.05940\n",
      "Epoch 36/100\n",
      " - 4s - loss: 0.2295 - acc: 0.5447 - val_loss: 0.0705 - val_acc: 0.9631\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.05940\n",
      "Epoch 37/100\n",
      " - 6s - loss: 0.2281 - acc: 0.5549 - val_loss: 0.0623 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.05940\n",
      "Epoch 38/100\n",
      " - 6s - loss: 0.2275 - acc: 0.5552 - val_loss: 0.0650 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.05940\n",
      "Epoch 39/100\n",
      " - 5s - loss: 0.2316 - acc: 0.5386 - val_loss: 0.0659 - val_acc: 0.9693\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.05940\n",
      "Epoch 40/100\n",
      " - 6s - loss: 0.2322 - acc: 0.5398 - val_loss: 0.0673 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.05940\n",
      "Epoch 41/100\n",
      " - 5s - loss: 0.2307 - acc: 0.5432 - val_loss: 0.0650 - val_acc: 0.9681\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.05940\n",
      "Epoch 42/100\n",
      " - 6s - loss: 0.2279 - acc: 0.5481 - val_loss: 0.0667 - val_acc: 0.9717\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.05940\n",
      "Epoch 43/100\n",
      " - 5s - loss: 0.2302 - acc: 0.5361 - val_loss: 0.0696 - val_acc: 0.9681\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.05940\n",
      "Epoch 44/100\n",
      " - 5s - loss: 0.2242 - acc: 0.5623 - val_loss: 0.0692 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.05940\n",
      "Epoch 45/100\n",
      " - 5s - loss: 0.2300 - acc: 0.5435 - val_loss: 0.0646 - val_acc: 0.9631\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.05940\n",
      "Epoch 46/100\n",
      " - 5s - loss: 0.2279 - acc: 0.5500 - val_loss: 0.0658 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.05940\n",
      "Epoch 47/100\n",
      " - 5s - loss: 0.2287 - acc: 0.5500 - val_loss: 0.0689 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.05940\n",
      "Epoch 48/100\n",
      " - 5s - loss: 0.2319 - acc: 0.5374 - val_loss: 0.0658 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.05940\n",
      "Epoch 49/100\n",
      " - 5s - loss: 0.2270 - acc: 0.5595 - val_loss: 0.0626 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.05940\n",
      "Epoch 50/100\n",
      " - 4s - loss: 0.2301 - acc: 0.5429 - val_loss: 0.0737 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.05940\n",
      "Epoch 51/100\n",
      " - 5s - loss: 0.2308 - acc: 0.5435 - val_loss: 0.0715 - val_acc: 0.9717\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.05940\n",
      "Epoch 52/100\n",
      " - 4s - loss: 0.2287 - acc: 0.5450 - val_loss: 0.0673 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.05940\n",
      "Epoch 53/100\n",
      " - 5s - loss: 0.2200 - acc: 0.5749 - val_loss: 0.0759 - val_acc: 0.9693\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.05940\n",
      "Epoch 54/100\n",
      " - 5s - loss: 0.2324 - acc: 0.5377 - val_loss: 0.0670 - val_acc: 0.9656\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.05940\n",
      "Epoch 55/100\n",
      " - 4s - loss: 0.2306 - acc: 0.5432 - val_loss: 0.0709 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.05940\n",
      "Epoch 56/100\n",
      " - 4s - loss: 0.2311 - acc: 0.5429 - val_loss: 0.0676 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.05940\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 5s - loss: 0.2369 - acc: 0.5217 - val_loss: 0.0624 - val_acc: 0.9742\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.05940\n",
      "Epoch 58/100\n",
      " - 5s - loss: 0.2299 - acc: 0.5460 - val_loss: 0.0664 - val_acc: 0.9693\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.05940\n",
      "Epoch 59/100\n",
      " - 4s - loss: 0.2320 - acc: 0.5358 - val_loss: 0.0640 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.05940\n",
      "Epoch 60/100\n",
      " - 5s - loss: 0.2270 - acc: 0.5475 - val_loss: 0.0627 - val_acc: 0.9681\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.05940\n",
      "Epoch 61/100\n",
      " - 7s - loss: 0.2278 - acc: 0.5420 - val_loss: 0.0645 - val_acc: 0.9631\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.05940\n",
      "Epoch 62/100\n",
      " - 5s - loss: 0.2275 - acc: 0.5453 - val_loss: 0.0764 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.05940\n",
      "Epoch 63/100\n",
      " - 4s - loss: 0.2270 - acc: 0.5533 - val_loss: 0.0660 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.05940\n",
      "Epoch 64/100\n",
      " - 4s - loss: 0.2320 - acc: 0.5340 - val_loss: 0.0708 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.05940\n",
      "Epoch 65/100\n",
      " - 5s - loss: 0.2288 - acc: 0.5453 - val_loss: 0.0780 - val_acc: 0.9631\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.05940\n",
      "Epoch 66/100\n",
      " - 5s - loss: 0.2275 - acc: 0.5484 - val_loss: 0.0682 - val_acc: 0.9656\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.05940\n",
      "Epoch 67/100\n",
      " - 4s - loss: 0.2319 - acc: 0.5370 - val_loss: 0.0725 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.05940\n",
      "Epoch 68/100\n",
      " - 4s - loss: 0.2274 - acc: 0.5466 - val_loss: 0.0631 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.05940\n",
      "Epoch 69/100\n",
      " - 4s - loss: 0.2295 - acc: 0.5380 - val_loss: 0.0630 - val_acc: 0.9717\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.05940\n",
      "Epoch 70/100\n",
      " - 5s - loss: 0.2293 - acc: 0.5438 - val_loss: 0.0630 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.05940\n",
      "Epoch 71/100\n",
      " - 5s - loss: 0.2251 - acc: 0.5533 - val_loss: 0.0638 - val_acc: 0.9681\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.05940\n",
      "Epoch 72/100\n",
      " - 5s - loss: 0.2307 - acc: 0.5374 - val_loss: 0.0746 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.05940\n",
      "Epoch 73/100\n",
      " - 5s - loss: 0.2299 - acc: 0.5463 - val_loss: 0.0654 - val_acc: 0.9717\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.05940\n",
      "Epoch 74/100\n",
      " - 4s - loss: 0.2317 - acc: 0.5358 - val_loss: 0.0677 - val_acc: 0.9656\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.05940\n",
      "Epoch 75/100\n",
      " - 5s - loss: 0.2236 - acc: 0.5586 - val_loss: 0.0690 - val_acc: 0.9693\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.05940\n",
      "Epoch 76/100\n",
      " - 4s - loss: 0.2295 - acc: 0.5450 - val_loss: 0.0679 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.05940\n",
      "Epoch 77/100\n",
      " - 4s - loss: 0.2280 - acc: 0.5472 - val_loss: 0.0633 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.05940\n",
      "Epoch 78/100\n",
      " - 4s - loss: 0.2261 - acc: 0.5530 - val_loss: 0.0713 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.05940\n",
      "Epoch 79/100\n",
      " - 4s - loss: 0.2284 - acc: 0.5404 - val_loss: 0.0665 - val_acc: 0.9656\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.05940\n",
      "Epoch 80/100\n",
      " - 4s - loss: 0.2301 - acc: 0.5361 - val_loss: 0.0698 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.05940\n",
      "Epoch 81/100\n",
      " - 5s - loss: 0.2237 - acc: 0.5533 - val_loss: 0.0650 - val_acc: 0.9717\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.05940\n",
      "Epoch 82/100\n",
      " - 4s - loss: 0.2268 - acc: 0.5512 - val_loss: 0.0703 - val_acc: 0.9693\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.05940\n",
      "Epoch 83/100\n",
      " - 5s - loss: 0.2260 - acc: 0.5463 - val_loss: 0.0664 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.05940\n",
      "Epoch 84/100\n",
      " - 5s - loss: 0.2308 - acc: 0.5377 - val_loss: 0.0680 - val_acc: 0.9693\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.05940\n",
      "Epoch 85/100\n",
      " - 5s - loss: 0.2338 - acc: 0.5266 - val_loss: 0.0619 - val_acc: 0.9656\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.05940\n",
      "Epoch 86/100\n",
      " - 5s - loss: 0.2298 - acc: 0.5441 - val_loss: 0.0671 - val_acc: 0.9631\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.05940\n",
      "Epoch 87/100\n",
      " - 5s - loss: 0.2277 - acc: 0.5463 - val_loss: 0.0687 - val_acc: 0.9644\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.05940\n",
      "Epoch 88/100\n",
      " - 5s - loss: 0.2324 - acc: 0.5327 - val_loss: 0.0622 - val_acc: 0.9656\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.05940\n",
      "Epoch 89/100\n",
      " - 4s - loss: 0.2231 - acc: 0.5613 - val_loss: 0.0700 - val_acc: 0.9656\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.05940\n",
      "Epoch 90/100\n",
      " - 4s - loss: 0.2311 - acc: 0.5272 - val_loss: 0.0674 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.05940\n",
      "Epoch 91/100\n",
      " - 4s - loss: 0.2299 - acc: 0.5423 - val_loss: 0.0700 - val_acc: 0.9668\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.05940\n",
      "Epoch 92/100\n",
      " - 5s - loss: 0.2247 - acc: 0.5589 - val_loss: 0.0670 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.05940\n",
      "Epoch 93/100\n",
      " - 4s - loss: 0.2262 - acc: 0.5410 - val_loss: 0.0655 - val_acc: 0.9681\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.05940\n",
      "Epoch 94/100\n",
      " - 5s - loss: 0.2287 - acc: 0.5432 - val_loss: 0.0574 - val_acc: 0.9693\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.05940 to 0.05745, saving model to model/weights.94-0.97.hdf5\n",
      "Epoch 95/100\n",
      " - 5s - loss: 0.2282 - acc: 0.5417 - val_loss: 0.0636 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.05745\n",
      "Epoch 96/100\n",
      " - 5s - loss: 0.2279 - acc: 0.5450 - val_loss: 0.0615 - val_acc: 0.9730\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.05745\n",
      "Epoch 97/100\n",
      " - 4s - loss: 0.2275 - acc: 0.5447 - val_loss: 0.0692 - val_acc: 0.9631\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.05745\n",
      "Epoch 98/100\n",
      " - 5s - loss: 0.2263 - acc: 0.5450 - val_loss: 0.0640 - val_acc: 0.9631\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.05745\n",
      "Epoch 99/100\n",
      " - 5s - loss: 0.2313 - acc: 0.5349 - val_loss: 0.0681 - val_acc: 0.9705\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.05745\n",
      "Epoch 100/100\n",
      " - 5s - loss: 0.2316 - acc: 0.5284 - val_loss: 0.0695 - val_acc: 0.9681\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.05745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12f38f860>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.expand_dims(X_train, axis=2), y_train_static_oh,\n",
    "          batch_size=32, epochs=100, verbose=2, validation_split=0.2, callbacks=[cp_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename highest epoch weight file to static.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"model/static.hdf5\"\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ TRAIN ACCURACY ------\n",
      "0.9916400295057782\n",
      "[[1275   11    0]\n",
      " [  23 1351    0]\n",
      " [   0    0 1407]]\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.predict(np.expand_dims(X_train, axis=2), batch_size=32)\n",
    "print(\"------ TRAIN ACCURACY ------\")\n",
    "print(accuracy_score(y_train, np.argmax(pred_train, axis=1)))\n",
    "print(confusion_matrix(y_train, np.argmax(pred_train, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ TEST ACCURACY ------\n",
      "0.9628205128205128\n",
      "[[447  44   0]\n",
      " [ 14 518   0]\n",
      " [  0   0 537]]\n"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict(np.expand_dims(X_test, axis=2), batch_size=32)\n",
    "print(\"------ TEST ACCURACY ------\")\n",
    "print(accuracy_score(y_test, np.argmax(pred_test, axis=1)))\n",
    "print(confusion_matrix(y_test, np.argmax(pred_test, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from numpy.random import seed\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = load_x(\"train\")   # at this stage, the data includes both dynamic and static HAR data\n",
    "y_train_all = load_y(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_all = load_x(\"test\")\n",
    "y_test_all = load_y(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_1 = np.where(y_train_all == 1)[0]\n",
    "dynamic_2 = np.where(y_train_all == 2)[0]\n",
    "dynamic_3 = np.where(y_train_all == 3)[0]\n",
    "dynamic = np.concatenate([dynamic_1, dynamic_2, dynamic_3])\n",
    "dynamic_list = dynamic.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = random.random()\n",
    "random.shuffle(dynamic_list, lambda: r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic = np.array(dynamic_list)\n",
    "\n",
    "X_train = X_train_all[dynamic]\n",
    "y_train = y_train_all[dynamic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train  = y_train - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_1 = np.where(y_test_all == 1)[0]\n",
    "dynamic_2 = np.where(y_test_all == 2)[0]\n",
    "dynamic_3 = np.where(y_test_all == 3)[0]\n",
    "dynamic = np.concatenate([dynamic_1, dynamic_2, dynamic_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test_all[dynamic]\n",
    "y_test = y_test_all[dynamic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test  = y_test - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_dynamic shape:  (1387, 561)\n"
     ]
    }
   ],
   "source": [
    "print(\"test_dynamic shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_dynamic_oh = np.eye(n_classes)[y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(2017)\n",
    "model = Sequential()\n",
    "model.add(Conv1D(100, 3, input_shape=(561, 1), activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.0004, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='mean_squared_error', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 559, 100)          400       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 186, 100)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 55803     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 56,203\n",
      "Trainable params: 56,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir = 'model/'\n",
    "if not os.path.exists(new_dir):\n",
    "    os.makedirs(new_dir)\n",
    "fpath = new_dir + 'weights.{epoch:02d}-{val_acc:.2f}.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_cb = ModelCheckpoint(fpath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2628 samples, validate on 657 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 0.2815 - acc: 0.4939 - val_loss: 0.1275 - val_acc: 0.8219\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12753, saving model to model/weights.01-0.82.hdf5\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.2479 - acc: 0.5396 - val_loss: 0.1106 - val_acc: 0.9072\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12753 to 0.11060, saving model to model/weights.02-0.91.hdf5\n",
      "Epoch 3/50\n",
      " - 1s - loss: 0.2416 - acc: 0.5464 - val_loss: 0.0855 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.11060 to 0.08546, saving model to model/weights.03-0.98.hdf5\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.2394 - acc: 0.5483 - val_loss: 0.0953 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.08546\n",
      "Epoch 5/50\n",
      " - 1s - loss: 0.2355 - acc: 0.5506 - val_loss: 0.0924 - val_acc: 0.9680\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08546\n",
      "Epoch 6/50\n",
      " - 1s - loss: 0.2367 - acc: 0.5548 - val_loss: 0.0864 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08546\n",
      "Epoch 7/50\n",
      " - 1s - loss: 0.2318 - acc: 0.5620 - val_loss: 0.0845 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.08546 to 0.08450, saving model to model/weights.07-0.98.hdf5\n",
      "Epoch 8/50\n",
      " - 1s - loss: 0.2305 - acc: 0.5643 - val_loss: 0.1066 - val_acc: 0.9482\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08450\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.2347 - acc: 0.5540 - val_loss: 0.1007 - val_acc: 0.9680\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08450\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.2252 - acc: 0.5753 - val_loss: 0.0800 - val_acc: 0.9680\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.08450 to 0.07997, saving model to model/weights.10-0.97.hdf5\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.2313 - acc: 0.5525 - val_loss: 0.0731 - val_acc: 0.9772\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.07997 to 0.07314, saving model to model/weights.11-0.98.hdf5\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.2313 - acc: 0.5533 - val_loss: 0.0753 - val_acc: 0.9817\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.07314\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.2328 - acc: 0.5548 - val_loss: 0.0822 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.07314\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.2308 - acc: 0.5518 - val_loss: 0.0801 - val_acc: 0.9711\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.07314\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.2271 - acc: 0.5628 - val_loss: 0.0974 - val_acc: 0.9574\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.07314\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.2326 - acc: 0.5506 - val_loss: 0.0803 - val_acc: 0.9848\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.07314\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.2266 - acc: 0.5712 - val_loss: 0.0861 - val_acc: 0.9711\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.07314\n",
      "Epoch 18/50\n",
      " - 1s - loss: 0.2284 - acc: 0.5639 - val_loss: 0.0776 - val_acc: 0.9787\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.07314\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.2268 - acc: 0.5696 - val_loss: 0.0899 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.07314\n",
      "Epoch 20/50\n",
      " - 1s - loss: 0.2314 - acc: 0.5540 - val_loss: 0.1012 - val_acc: 0.9543\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.07314\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.2310 - acc: 0.5441 - val_loss: 0.0834 - val_acc: 0.9741\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.07314\n",
      "Epoch 22/50\n",
      " - 1s - loss: 0.2282 - acc: 0.5609 - val_loss: 0.0871 - val_acc: 0.9696\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.07314\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.2307 - acc: 0.5544 - val_loss: 0.0834 - val_acc: 0.9772\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.07314\n",
      "Epoch 24/50\n",
      " - 1s - loss: 0.2301 - acc: 0.5544 - val_loss: 0.0923 - val_acc: 0.9696\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.07314\n",
      "Epoch 25/50\n",
      " - 1s - loss: 0.2256 - acc: 0.5666 - val_loss: 0.0829 - val_acc: 0.9817\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.07314\n",
      "Epoch 26/50\n",
      " - 1s - loss: 0.2238 - acc: 0.5818 - val_loss: 0.0919 - val_acc: 0.9680\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.07314\n",
      "Epoch 27/50\n",
      " - 1s - loss: 0.2300 - acc: 0.5563 - val_loss: 0.0759 - val_acc: 0.9726\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.07314\n",
      "Epoch 28/50\n",
      " - 1s - loss: 0.2275 - acc: 0.5529 - val_loss: 0.0824 - val_acc: 0.9756\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.07314\n",
      "Epoch 29/50\n",
      " - 1s - loss: 0.2313 - acc: 0.5510 - val_loss: 0.0968 - val_acc: 0.9559\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.07314\n",
      "Epoch 30/50\n",
      " - 1s - loss: 0.2283 - acc: 0.5521 - val_loss: 0.0789 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.07314\n",
      "Epoch 31/50\n",
      " - 1s - loss: 0.2316 - acc: 0.5464 - val_loss: 0.0893 - val_acc: 0.9650\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.07314\n",
      "Epoch 32/50\n",
      " - 1s - loss: 0.2275 - acc: 0.5662 - val_loss: 0.1045 - val_acc: 0.9589\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.07314\n",
      "Epoch 33/50\n",
      " - 1s - loss: 0.2299 - acc: 0.5491 - val_loss: 0.0813 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.07314\n",
      "Epoch 34/50\n",
      " - 1s - loss: 0.2335 - acc: 0.5430 - val_loss: 0.0829 - val_acc: 0.9817\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.07314\n",
      "Epoch 35/50\n",
      " - 1s - loss: 0.2219 - acc: 0.5742 - val_loss: 0.1031 - val_acc: 0.9543\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.07314\n",
      "Epoch 36/50\n",
      " - 1s - loss: 0.2325 - acc: 0.5495 - val_loss: 0.0732 - val_acc: 0.9619\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.07314\n",
      "Epoch 37/50\n",
      " - 1s - loss: 0.2287 - acc: 0.5605 - val_loss: 0.0822 - val_acc: 0.9848\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.07314\n",
      "Epoch 38/50\n",
      " - 1s - loss: 0.2296 - acc: 0.5548 - val_loss: 0.0895 - val_acc: 0.9711\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.07314\n",
      "Epoch 39/50\n",
      " - 1s - loss: 0.2287 - acc: 0.5571 - val_loss: 0.0848 - val_acc: 0.9711\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.07314\n",
      "Epoch 40/50\n",
      " - 1s - loss: 0.2321 - acc: 0.5445 - val_loss: 0.0751 - val_acc: 0.9817\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.07314\n",
      "Epoch 41/50\n",
      " - 1s - loss: 0.2290 - acc: 0.5533 - val_loss: 0.0827 - val_acc: 0.9863\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.07314\n",
      "Epoch 42/50\n",
      " - 1s - loss: 0.2288 - acc: 0.5586 - val_loss: 0.0743 - val_acc: 0.9878\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.07314\n",
      "Epoch 43/50\n",
      " - 1s - loss: 0.2273 - acc: 0.5540 - val_loss: 0.0761 - val_acc: 0.9863\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.07314\n",
      "Epoch 44/50\n",
      " - 1s - loss: 0.2219 - acc: 0.5750 - val_loss: 0.0844 - val_acc: 0.9833\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.07314\n",
      "Epoch 45/50\n",
      " - 1s - loss: 0.2261 - acc: 0.5662 - val_loss: 0.0885 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.07314\n",
      "Epoch 46/50\n",
      " - 1s - loss: 0.2236 - acc: 0.5723 - val_loss: 0.0801 - val_acc: 0.9772\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.07314\n",
      "Epoch 47/50\n",
      " - 1s - loss: 0.2287 - acc: 0.5495 - val_loss: 0.0847 - val_acc: 0.9680\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.07314\n",
      "Epoch 48/50\n",
      " - 1s - loss: 0.2244 - acc: 0.5662 - val_loss: 0.0891 - val_acc: 0.9604\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.07314\n",
      "Epoch 49/50\n",
      " - 1s - loss: 0.2210 - acc: 0.5750 - val_loss: 0.0797 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.07314\n",
      "Epoch 50/50\n",
      " - 1s - loss: 0.2278 - acc: 0.5537 - val_loss: 0.0770 - val_acc: 0.9802\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.07314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x103b301d0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.expand_dims(X_train, axis=2), y_train_dynamic_oh,\n",
    "          batch_size=32, epochs=50, verbose=2, validation_split=0.2,\n",
    "          callbacks=[cp_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rename highest epoch weight file to dynamic.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"model/dynamic.hdf5\"\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ TRAIN ACCURACY ------\n",
      "0.9933028919330289\n",
      "[[1219    6    1]\n",
      " [   0 1071    2]\n",
      " [   0   13  973]]\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.predict(np.expand_dims(X_train, axis=2), batch_size=32)\n",
    "print(\"------ TRAIN ACCURACY ------\")\n",
    "print(accuracy_score(y_train, np.argmax(pred_train, axis=1)))\n",
    "print(confusion_matrix(y_train, np.argmax(pred_train, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ TEST ACCURACY ------\n",
      "0.9776496034607065\n",
      "[[493   1   2]\n",
      " [ 12 459   0]\n",
      " [  3  13 404]]\n"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict(np.expand_dims(X_test, axis=2), batch_size=32)\n",
    "print(\"------ TEST ACCURACY ------\")\n",
    "print(accuracy_score(y_test, np.argmax(pred_test, axis=1)))\n",
    "print(confusion_matrix(y_test, np.argmax(pred_test, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static Sharpening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import load_model\n",
    "import random\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "alpha = np.arange(0.01, 0.31, 0.01)\n",
    "sigma = np.arange(5, 10, 1)\n",
    "def display_output_x(title_str, X, y):\n",
    "\n",
    "    # Load static HAR model\n",
    "    model_path = \"model/static.hdf5\"\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    print(\"\\n=== COMPARE ACCURACY: NO SHARPEN vs. SHARPENED  ===\")\n",
    "    print(\"===         Test Data: {} Half         ===\\n\".format(title_str))\n",
    "\n",
    "    pred_dyna_raw = model.predict(np.expand_dims(X, axis=2), batch_size=32)\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"       NO SHARPEN ACCURACY       \")\n",
    "    print(\"---------------------------------\")\n",
    "    print(accuracy_score(y, np.argmax(pred_dyna_raw, axis=1)))\n",
    "    print(confusion_matrix(y, np.argmax(pred_dyna_raw, axis=1)))\n",
    "\n",
    "    alpha = np.arange(0.01, 0.31, 0.01)\n",
    "    sigma = np.arange(5, 10, 1)\n",
    "    \n",
    "    for s in sigma:\n",
    "        new_list = []\n",
    "        for a in alpha:\n",
    "            # Sharpen test data with various sigma (for Gaussian filter) and alpha value combinations\n",
    "            X_test_sharpen = sharpen(X, s, a)\n",
    "            pred_dyna_sharpen = model.predict(np.expand_dims(X_test_sharpen, axis=2), batch_size=32)\n",
    "            new_list.append(accuracy_score(y, np.argmax(pred_dyna_sharpen, axis=1)))\n",
    "        list_new = np.array(new_list)    \n",
    "        accuracy_list.append(alpha[np.argmax(new_list)])\n",
    "    \n",
    "    print(\"\\n---------------------------------\")\n",
    "    print(\"       SHARPENED  ACCURACY       \")\n",
    "    print(\"---------------------------------\")\n",
    "    s = 5\n",
    "    for a in accuracy_list:\n",
    "        X_test_sharpen = sharpen(X, s, a)\n",
    "        pred_dyna_sharpen = model.predict(np.expand_dims(X_test_sharpen, axis=2), batch_size=32)\n",
    "        print(\">>> sigma={}, alpha={:.2f}\".format(s, a))\n",
    "        print(accuracy_score(y, np.argmax(pred_dyna_sharpen, axis=1)))\n",
    "        print(confusion_matrix(y, np.argmax(pred_dyna_sharpen, axis=1)))\n",
    "        s = s + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = load_x(\"test\")\n",
    "y_test = load_y(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 818"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "stat_1 = list(np.where(y_test == 4)[0])\n",
    "temp = int(len(stat_1) * 0.5)\n",
    "stat_1_first = random.sample(stat_1, temp)\n",
    "stat_1_second = list(set(stat_1) - set(stat_1_first))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "stat_2 = list(np.where(y_test == 5)[0])\n",
    "stat_2_first = random.sample(stat_2, int(len(stat_2) * 0.5))\n",
    "stat_2_second = list(set(stat_2) - set(stat_2_first))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "stat_3 = list(np.where(y_test == 6)[0])\n",
    "stat_3_first = random.sample(stat_3, int(len(stat_3) * 0.5))\n",
    "stat_3_second = list(set(stat_3) - set(stat_3_first))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_first = np.concatenate([stat_1_first, stat_2_first, stat_3_first])\n",
    "static_second = np.concatenate([stat_1_second, stat_2_second, stat_3_second])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_static_first shape:  (779, 561)\n"
     ]
    }
   ],
   "source": [
    "X_test_first = X_test[static_first]\n",
    "y_test_first = y_test[static_first] - 4   # Convert (4, 5, 6) labels to (0, 1, 2)\n",
    "print(\"test_static_first shape: \", X_test_first.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_static_second shape:  (781, 561)\n"
     ]
    }
   ],
   "source": [
    "X_test_second = X_test[static_second]\n",
    "y_test_second = y_test[static_second] - 4   # Convert (4, 5, 6) labels to (0, 1, 2)\n",
    "print(\"test_static_second shape: \", X_test_second.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COMPARE ACCURACY: NO SHARPEN vs. SHARPENED  ===\n",
      "===         Test Data: First Half         ===\n",
      "\n",
      "---------------------------------\n",
      "       NO SHARPEN ACCURACY       \n",
      "---------------------------------\n",
      "0.9576379974326059\n",
      "[[219  26   0]\n",
      " [  7 259   0]\n",
      " [  0   0 268]]\n",
      "\n",
      "---------------------------------\n",
      "       SHARPENED  ACCURACY       \n",
      "---------------------------------\n",
      ">>> sigma=5, alpha=0.18\n",
      "0.9640564826700898\n",
      "[[228  17   0]\n",
      " [ 11 255   0]\n",
      " [  0   0 268]]\n",
      ">>> sigma=6, alpha=0.15\n",
      "0.9640564826700898\n",
      "[[228  17   0]\n",
      " [ 11 255   0]\n",
      " [  0   0 268]]\n",
      ">>> sigma=7, alpha=0.14\n",
      "0.9640564826700898\n",
      "[[228  17   0]\n",
      " [ 11 255   0]\n",
      " [  0   0 268]]\n",
      ">>> sigma=8, alpha=0.14\n",
      "0.9640564826700898\n",
      "[[228  17   0]\n",
      " [ 11 255   0]\n",
      " [  0   0 268]]\n",
      ">>> sigma=9, alpha=0.14\n",
      "0.9640564826700898\n",
      "[[228  17   0]\n",
      " [ 11 255   0]\n",
      " [  0   0 268]]\n"
     ]
    }
   ],
   "source": [
    "display_output_x(\"First\", X_test_first, y_test_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COMPARE ACCURACY: NO SHARPEN vs. SHARPENED  ===\n",
      "===         Test Data: Second Half         ===\n",
      "\n",
      "---------------------------------\n",
      "       NO SHARPEN ACCURACY       \n",
      "---------------------------------\n",
      "0.967989756722151\n",
      "[[228  18   0]\n",
      " [  7 259   0]\n",
      " [  0   0 269]]\n",
      "\n",
      "---------------------------------\n",
      "       SHARPENED  ACCURACY       \n",
      "---------------------------------\n",
      ">>> sigma=5, alpha=0.01\n",
      "0.9641485275288092\n",
      "[[228  18   0]\n",
      " [ 10 256   0]\n",
      " [  0   0 269]]\n",
      ">>> sigma=6, alpha=0.01\n",
      "0.9641485275288092\n",
      "[[228  18   0]\n",
      " [ 10 256   0]\n",
      " [  0   0 269]]\n",
      ">>> sigma=7, alpha=0.15\n",
      "0.9654289372599232\n",
      "[[232  14   0]\n",
      " [ 13 253   0]\n",
      " [  0   0 269]]\n",
      ">>> sigma=8, alpha=0.14\n",
      "0.9654289372599232\n",
      "[[232  14   0]\n",
      " [ 13 253   0]\n",
      " [  0   0 269]]\n",
      ">>> sigma=9, alpha=0.01\n",
      "0.9641485275288092\n",
      "[[228  18   0]\n",
      " [ 10 256   0]\n",
      " [  0   0 269]]\n"
     ]
    }
   ],
   "source": [
    "display_output_x(\"Second\", X_test_second, y_test_second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By cross checking both the sets we can conclude that s = 8 and alpha = 0.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Sharpening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import load_model\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_output_x(title_str, X, y):\n",
    "\n",
    "    # Load static HAR model\n",
    "    model_path = \"model/dynamic.hdf5\"\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    print(\"\\n=== COMPARE ACCURACY: NO SHARPEN vs. SHARPENED  ===\")\n",
    "    print(\"===         Test Data: {} Half         ===\\n\".format(title_str))\n",
    "\n",
    "    pred_dyna_raw = model.predict(np.expand_dims(X, axis=2), batch_size=32)\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"       NO SHARPEN ACCURACY       \")\n",
    "    print(\"---------------------------------\")\n",
    "    print(accuracy_score(y, np.argmax(pred_dyna_raw, axis=1)))\n",
    "    print(confusion_matrix(y, np.argmax(pred_dyna_raw, axis=1)))\n",
    "\n",
    "    alpha = np.arange(0.05, 2.55, 0.05)\n",
    "    sigma = np.arange(5, 10, 1)\n",
    "    accuracy_list = []\n",
    "    for s in sigma:\n",
    "        new_list = []\n",
    "        for a in alpha:\n",
    "            # Sharpen test data with various sigma (for Gaussian filter) and alpha value combinations\n",
    "            X_test_sharpen = sharpen(X, s, a)\n",
    "            pred_dyna_sharpen = model.predict(np.expand_dims(X_test_sharpen, axis=2), batch_size=32)\n",
    "            new_list.append(accuracy_score(y, np.argmax(pred_dyna_sharpen, axis=1)))\n",
    "        list_new = np.array(new_list)    \n",
    "        accuracy_list.append(alpha[np.argmax(new_list)])\n",
    "    \n",
    "    print(\"\\n---------------------------------\")\n",
    "    print(\"       SHARPENED  ACCURACY       \")\n",
    "    print(\"---------------------------------\")\n",
    "    s = 5\n",
    "    for a in accuracy_list:\n",
    "        X_test_sharpen = sharpen(X, s, a)\n",
    "        pred_dyna_sharpen = model.predict(np.expand_dims(X_test_sharpen, axis=2), batch_size=32)\n",
    "        print(\">>> sigma={}, alpha={:.2f}\".format(s, a))\n",
    "        print(accuracy_score(y, np.argmax(pred_dyna_sharpen, axis=1)))\n",
    "        print(confusion_matrix(y, np.argmax(pred_dyna_sharpen, axis=1)))\n",
    "        s = s + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = load_x(\"test\")\n",
    "y_test = load_y(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "dyna_1 = list(np.where(y_test == 1)[0])\n",
    "dyna_1_first = random.sample(dyna_1, int(len(dyna_1) * 0.5))\n",
    "dyna_1_second = list(set(dyna_1) - set(dyna_1_first))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "dyna_2 = list(np.where(y_test == 2)[0])\n",
    "dyna_2_first = random.sample(dyna_2, int(len(dyna_2) * 0.5))\n",
    "dyna_2_second = list(set(dyna_2) - set(dyna_2_first))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "dyna_3 = list(np.where(y_test == 3)[0])\n",
    "dyna_3_first = random.sample(dyna_3, int(len(dyna_3) * 0.5))\n",
    "dyna_3_second = list(set(dyna_3) - set(dyna_3_first))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_first = np.concatenate([dyna_1_first, dyna_2_first, dyna_3_first])\n",
    "dynamic_second = np.concatenate([dyna_1_second, dyna_2_second, dyna_3_second])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_dynamic_first shape:  (693, 561)\n"
     ]
    }
   ],
   "source": [
    "X_test_first = X_test[dynamic_first]\n",
    "y_test_first = y_test[dynamic_first] - 1   # Convert (1, 2, 3) labels to (0, 1, 2)\n",
    "print(\"test_dynamic_first shape: \", X_test_first.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_dynamic_second shape:  (694, 561)\n"
     ]
    }
   ],
   "source": [
    "X_test_second = X_test[dynamic_second]\n",
    "y_test_second = y_test[dynamic_second] - 1  \n",
    "# Convert (1, 2, 3) labels to (0, 1, 2)\n",
    "print(\"test_dynamic_second shape: \", X_test_second.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COMPARE ACCURACY: NO SHARPEN vs. SHARPENED  ===\n",
      "===         Test Data: First Half         ===\n",
      "\n",
      "---------------------------------\n",
      "       NO SHARPEN ACCURACY       \n",
      "---------------------------------\n",
      "0.9841269841269841\n",
      "[[247   1   0]\n",
      " [  5 230   0]\n",
      " [  0   5 205]]\n",
      "\n",
      "---------------------------------\n",
      "       SHARPENED  ACCURACY       \n",
      "---------------------------------\n",
      ">>> sigma=5, alpha=0.05\n",
      "0.9855699855699855\n",
      "[[247   1   0]\n",
      " [  5 230   0]\n",
      " [  0   4 206]]\n",
      ">>> sigma=6, alpha=0.05\n",
      "0.9841269841269841\n",
      "[[247   1   0]\n",
      " [  6 229   0]\n",
      " [  0   4 206]]\n",
      ">>> sigma=7, alpha=0.05\n",
      "0.9841269841269841\n",
      "[[247   1   0]\n",
      " [  6 229   0]\n",
      " [  0   4 206]]\n",
      ">>> sigma=8, alpha=0.05\n",
      "0.9841269841269841\n",
      "[[247   1   0]\n",
      " [  6 229   0]\n",
      " [  0   4 206]]\n",
      ">>> sigma=9, alpha=0.05\n",
      "0.9841269841269841\n",
      "[[247   1   0]\n",
      " [  6 229   0]\n",
      " [  0   4 206]]\n"
     ]
    }
   ],
   "source": [
    "display_output_x(\"First\", X_test_first, y_test_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COMPARE ACCURACY: NO SHARPEN vs. SHARPENED  ===\n",
      "===         Test Data: Second Half         ===\n",
      "\n",
      "---------------------------------\n",
      "       NO SHARPEN ACCURACY       \n",
      "---------------------------------\n",
      "0.9711815561959655\n",
      "[[246   0   2]\n",
      " [  7 229   0]\n",
      " [  3   8 199]]\n",
      "\n",
      "---------------------------------\n",
      "       SHARPENED  ACCURACY       \n",
      "---------------------------------\n",
      ">>> sigma=5, alpha=0.10\n",
      "0.9697406340057637\n",
      "[[244   1   3]\n",
      " [  7 229   0]\n",
      " [  2   8 200]]\n",
      ">>> sigma=6, alpha=0.10\n",
      "0.9697406340057637\n",
      "[[244   1   3]\n",
      " [  7 229   0]\n",
      " [  2   8 200]]\n",
      ">>> sigma=7, alpha=0.05\n",
      "0.9697406340057637\n",
      "[[245   0   3]\n",
      " [  7 229   0]\n",
      " [  3   8 199]]\n",
      ">>> sigma=8, alpha=0.05\n",
      "0.9697406340057637\n",
      "[[245   0   3]\n",
      " [  7 229   0]\n",
      " [  3   8 199]]\n",
      ">>> sigma=9, alpha=0.05\n",
      "0.9697406340057637\n",
      "[[245   0   3]\n",
      " [  7 229   0]\n",
      " [  3   8 199]]\n"
     ]
    }
   ],
   "source": [
    "display_output_x(\"Second\", X_test_second, y_test_second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By cross checking both the sets we can conclude that s = 8 and alpha = 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_output_dyna(X, y,s,a):\n",
    "\n",
    "    # Load static HAR model\n",
    "    model_path = \"model/dynamic.hdf5\"\n",
    "    model = load_model(model_path)\n",
    "            # Sharpen test data with various sigma (for Gaussian filter) and alpha value combinations\n",
    "    X_test_sharpen = sharpen(X, s, a)\n",
    "    pred_dyna_sharpen = model.predict(np.expand_dims(X_test_sharpen, axis=2), batch_size=32)\n",
    "    print('------------')\n",
    "    print('Dynamic')\n",
    "    print('------------')\n",
    "    print(\"Accuracy : \",accuracy_score(y, np.argmax(pred_dyna_sharpen, axis=1)))\n",
    "    label = [\"WALKING\", \"WALKING_UPSTAIRS\", \"WALKING_DOWNSTAIRS\"]\n",
    "    frame_confusion = pd.DataFrame(confusion_matrix(y, np.argmax(pred_dyna_sharpen, axis=1)), \n",
    "                                   index = label, columns = label)\n",
    "\n",
    "    sns.heatmap(frame_confusion, annot = True, fmt=\"d\", cmap=\"YlGnBu\", linewidths=.5)\n",
    "    plt.title(\"Test confusion matrix\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Dynamic\n",
      "------------\n",
      "Accuracy :  0.976928622927181\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_output_dyna( X_test, y_test,8,0.04 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_output_stat(X, y,s,a):\n",
    "\n",
    "    # Load static HAR model\n",
    "    model_path = \"model/static.hdf5\"\n",
    "    model = load_model(model_path)\n",
    "            # Sharpen test data with various sigma (for Gaussian filter) and alpha value combinations\n",
    "    X_test_sharpen = sharpen(X, s, a)\n",
    "    pred_dyna_sharpen = model.predict(np.expand_dims(X_test_sharpen, axis=2), batch_size=32)\n",
    "    print('------------')\n",
    "    print('Static')\n",
    "    print('------------')\n",
    "    print(\"Accuracy : \",accuracy_score(y, np.argmax(pred_dyna_sharpen, axis=1)))\n",
    "    label = [\"SITTING\", \"STANDING\", \"LYING\"]\n",
    "    frame_confusion = pd.DataFrame(confusion_matrix(y, np.argmax(pred_dyna_sharpen, axis=1)), \n",
    "                                   index = label, columns = label)\n",
    "\n",
    "    sns.heatmap(frame_confusion, annot = True, fmt=\"d\", cmap=\"YlGnBu\", linewidths=.5)\n",
    "    plt.title(\"Test confusion matrix\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------\n",
      "Static\n",
      "------------\n",
      "Accuracy :  0.9647435897435898\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_output_stat( X_test, y_test,8,0.14 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------------+------------------------------+----------+\n",
      "|     Model     | Hyper-parameters (units) | Hyper-parameters (Drop-outs) | Accuracy |\n",
      "+---------------+--------------------------+------------------------------+----------+\n",
      "|      LSTM     |            64            |          D1 - 0.233          |  0.9199  |\n",
      "| LSTM 2-layers |            64            |    D1 - 0.425, D2 - 0.233    |  0.8979  |\n",
      "+---------------+--------------------------+------------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"Model\",\"Hyper-parameters (units)\",\"Hyper-parameters (Drop-outs)\" ,\"Accuracy\"]\n",
    "x.add_row([\"LSTM\", 64, \"D1 - 0.233\", 0.9199])\n",
    "x.add_row([\"LSTM 2-layers\", 64, \"D1 - 0.425, D2 - 0.233\", 0.8979])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------+----------+\n",
      "|                        Model                         | Accuracy |\n",
      "+------------------------------------------------------+----------+\n",
      "|             CNN + CNN + MP + DO + Dense              |  0.9199  |\n",
      "|                CNN + MP + DO + Dense                 |  0.9056  |\n",
      "| TimeDistributed(CNN + MP + CNN  + MP) + LSTM + Dense |  0.8992  |\n",
      "+------------------------------------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"Model\", \"Accuracy\"]\n",
    "x.add_row([\"CNN + CNN + MP + DO + Dense\",  0.9199])\n",
    "x.add_row([\"CNN + MP + DO + Dense\", 0.9056])\n",
    "x.add_row([\"TimeDistributed(CNN + MP + CNN  + MP) + LSTM + Dense\", 0.8992])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+---------+-------+-------+----------+\n",
      "|        Model        |  Split  | Sigma | Alpha | Accuracy |\n",
      "+---------------------+---------+-------+-------+----------+\n",
      "| CNN + Test Sharping | Dynamic |   8   |  0.04 |  0.9796  |\n",
      "| CNN + Test Sharping |  Static |   8   |  0.14 |  0.9647  |\n",
      "+---------------------+---------+-------+-------+----------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "x = PrettyTable()\n",
    "x.field_names = [\"Model\", \"Split\",\"Sigma\", \"Alpha\",\"Accuracy\"]\n",
    "x.add_row([\"CNN + Test Sharping\", \"Dynamic\", 8 , 0.04 , 0.9796])\n",
    "x.add_row([\"CNN + Test Sharping\", \"Static\", 8, 0.14, 0.9647])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step followed in case study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ____Step 1____ : Fetched data from raw dataset.\n",
    " - ____Step 2____ : Applied dataset on various LSTM Architectures.\n",
    " - ____Step 3____ : Applied dataset on various CNN Architectures. \n",
    " - ____Step 4____ : Since LSTM and CNN have a cap of 92%, split dataset features into 2 categories static and dynamic.\n",
    " - ____Step 5____ : Applied CNN on 2 seperate datasets and saved their model weights in files static.hdf5 and dynamic.hdf5.\n",
    " - ____Step 6____ : Again split the categories into subsets of 2 for each category.\n",
    " - ____Step 7____ : The above method is helpful in determining sigma and alpha values for sharpening.\n",
    " - ____Step 7____ : Finally converged the model into 2 seperate model, one predicting static and other dynamic.\n",
    " \n",
    " - ____Observations____ : In the following case study, static gave an accuracy of 96.47% and dynamic an accuracy of 97.96%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5949027/\n",
    "https://github.com/heeryoncho/sensors2018cnnhar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
